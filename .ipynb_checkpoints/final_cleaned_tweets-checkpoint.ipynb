{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"trump_tweets_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### emojis, urls, make lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5088, 16)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dow just crashes through 25,000. Congrats! Big cuts in unnecessary regulations continuing.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[60, \"cleaned_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5                                   Thank you Nicole! \n",
       "6      U.S. Stock Market up almost 20% since Election!\n",
       "7    Thank you to Shawn Steel for the nice words on...\n",
       "8     Great night in Iowa - special people. Thank you!\n",
       "9                            MAKE AMERICA GREAT AGAIN!\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[5:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweet-preprocessor\n",
      "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
      "Installing collected packages: tweet-preprocessor\n",
      "Successfully installed tweet-preprocessor-0.6.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming a separate feature for cleaned tweets\n",
    "#for i,v in enumerate(df['cleaned_text']):\n",
    "   # df.loc[v,['cleaned_text']] = p.clean(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def preprocess_tweet(row):\n",
    " #   text = row['cleaned_text']\n",
    "  #  text = p.clean(text)\n",
    "  #  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5088):\n",
    "    df.loc[i,'cleaned_text2'] = remove_emoji(df.loc[i,'cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the democrats are all talk and no action. they are doing nothing to fix daca. great opportunity missed. too bad! america first! '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5087,\"cleaned_text2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"trump_tweets_cleaned_2.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0,5088):\n",
    " #   df.loc[i,'cleaned_text2'] = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])\",\" \", df.loc[i,'cleaned_text2']).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed @ mentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5088):\n",
    "    df.loc[i,'cleaned_text2'] = re.sub(\"@[A-Za-z0-9]+\",\"\",df.loc[i,'cleaned_text2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>date_new</th>\n",
       "      <th>date_part</th>\n",
       "      <th>time_part</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>compound</th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>cleaned_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.384230e+17</td>\n",
       "      <td>make america great again!</td>\n",
       "      <td>157963</td>\n",
       "      <td>37189</td>\n",
       "      <td>2017-06-12 15:00:00</td>\n",
       "      <td>2017-06-12 23:00:00</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'comp...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>make america great again!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.391890e+17</td>\n",
       "      <td>make america great again!</td>\n",
       "      <td>56596</td>\n",
       "      <td>11433</td>\n",
       "      <td>2017-08-12 17:46:00</td>\n",
       "      <td>2017-08-13 01:46:00</td>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>01:46:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'comp...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>make america great again!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.353400e+17</td>\n",
       "      <td>thank you rand!</td>\n",
       "      <td>42793</td>\n",
       "      <td>9125</td>\n",
       "      <td>2017-11-28 02:50:00</td>\n",
       "      <td>2017-11-28 10:50:00</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>10:50:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>['Rand']</td>\n",
       "      <td>['ORG']</td>\n",
       "      <td>thank you rand!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.253890e+17</td>\n",
       "      <td>thank you @luisriveramarin!</td>\n",
       "      <td>23521</td>\n",
       "      <td>4574</td>\n",
       "      <td>2017-10-31 15:48:00</td>\n",
       "      <td>2017-10-31 23:48:00</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>23:48:00</td>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>thank you !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.997980e+17</td>\n",
       "      <td>join me live from fort myer in arlington, virg...</td>\n",
       "      <td>36009</td>\n",
       "      <td>4891</td>\n",
       "      <td>2017-08-22 01:00:00</td>\n",
       "      <td>2017-08-22 09:00:00</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.804, 'pos': 0.196, 'comp...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>['Fort Myer', 'Arlington', 'Virginia', '➡']</td>\n",
       "      <td>['GPE', 'GPE', 'GPE', 'ORG']</td>\n",
       "      <td>join me live from fort myer in arlington, virg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                       cleaned_text  favorites  \\\n",
       "0  9.384230e+17                          make america great again!     157963   \n",
       "1  9.391890e+17                         make america great again!       56596   \n",
       "2  9.353400e+17                                   thank you rand!       42793   \n",
       "3  9.253890e+17                       thank you @luisriveramarin!       23521   \n",
       "4  8.997980e+17  join me live from fort myer in arlington, virg...      36009   \n",
       "\n",
       "   retweets                 date             date_new   date_part time_part  \\\n",
       "0     37189  2017-06-12 15:00:00  2017-06-12 23:00:00  2017-06-12  23:00:00   \n",
       "1     11433  2017-08-12 17:46:00  2017-08-13 01:46:00  2017-08-13  01:46:00   \n",
       "2      9125  2017-11-28 02:50:00  2017-11-28 10:50:00  2017-11-28  10:50:00   \n",
       "3      4574  2017-10-31 15:48:00  2017-10-31 23:48:00  2017-10-31  23:48:00   \n",
       "4      4891  2017-08-22 01:00:00  2017-08-22 09:00:00  2017-08-22  09:00:00   \n",
       "\n",
       "   hour  year  month                                    sentiment_score  \\\n",
       "0    23  2017      6  {'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'comp...   \n",
       "1     1  2017      8  {'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'comp...   \n",
       "2    10  2017     11  {'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...   \n",
       "3    23  2017     10  {'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...   \n",
       "4     9  2017      8  {'neg': 0.0, 'neu': 0.804, 'pos': 0.196, 'comp...   \n",
       "\n",
       "   tweet_length  compound                                       entity  \\\n",
       "0            25    0.6588                                           []   \n",
       "1            26    0.6588                                           []   \n",
       "2            16    0.4199                                     ['Rand']   \n",
       "3            28    0.4199                                           []   \n",
       "4            54    0.2960  ['Fort Myer', 'Arlington', 'Virginia', '➡']   \n",
       "\n",
       "                    entity_type  \\\n",
       "0                            []   \n",
       "1                            []   \n",
       "2                       ['ORG']   \n",
       "3                            []   \n",
       "4  ['GPE', 'GPE', 'GPE', 'ORG']   \n",
       "\n",
       "                                       cleaned_text2  \n",
       "0                          make america great again!  \n",
       "1                         make america great again!   \n",
       "2                                   thank you rand!   \n",
       "3                                       thank you !   \n",
       "4  join me live from fort myer in arlington, virg...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dow just crashes through 25,000. congrats! big cuts in unnecessary regulations continuing.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1:100,\"cleaned_text2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
