{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"trump_tweets_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### emojis, urls, make lowercase,punctuation, hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5088, 16)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweet-preprocessor\n",
      "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
      "Installing collected packages: tweet-preprocessor\n",
      "Successfully installed tweet-preprocessor-0.6.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5088):\n",
    "    df.loc[i,'cleaned_text2'] = remove_emoji(df.loc[i,'cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the democrats are all talk and no action. they are doing nothing to fix daca. great opportunity missed. too bad! america first! '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5087,\"cleaned_text2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"trump_tweets_cleaned_2.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>date_new</th>\n",
       "      <th>date_part</th>\n",
       "      <th>time_part</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>compound</th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>cleaned_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.384230e+17</td>\n",
       "      <td>make america great again!</td>\n",
       "      <td>157963</td>\n",
       "      <td>37189</td>\n",
       "      <td>2017-06-12 15:00:00</td>\n",
       "      <td>2017-06-12 23:00:00</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'comp...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>make america great again!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.391890e+17</td>\n",
       "      <td>make america great again!</td>\n",
       "      <td>56596</td>\n",
       "      <td>11433</td>\n",
       "      <td>2017-08-12 17:46:00</td>\n",
       "      <td>2017-08-13 01:46:00</td>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>01:46:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'comp...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>make america great again!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.353400e+17</td>\n",
       "      <td>thank you rand!</td>\n",
       "      <td>42793</td>\n",
       "      <td>9125</td>\n",
       "      <td>2017-11-28 02:50:00</td>\n",
       "      <td>2017-11-28 10:50:00</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>10:50:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>['Rand']</td>\n",
       "      <td>['ORG']</td>\n",
       "      <td>thank you rand!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.253890e+17</td>\n",
       "      <td>thank you @luisriveramarin!</td>\n",
       "      <td>23521</td>\n",
       "      <td>4574</td>\n",
       "      <td>2017-10-31 15:48:00</td>\n",
       "      <td>2017-10-31 23:48:00</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>23:48:00</td>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>thank you !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.997980e+17</td>\n",
       "      <td>join me live from fort myer in arlington, virg...</td>\n",
       "      <td>36009</td>\n",
       "      <td>4891</td>\n",
       "      <td>2017-08-22 01:00:00</td>\n",
       "      <td>2017-08-22 09:00:00</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.804, 'pos': 0.196, 'comp...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>['Fort Myer', 'Arlington', 'Virginia', '➡']</td>\n",
       "      <td>['GPE', 'GPE', 'GPE', 'ORG']</td>\n",
       "      <td>join me live from fort myer in arlington, virg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                       cleaned_text  favorites  \\\n",
       "0  9.384230e+17                          make america great again!     157963   \n",
       "1  9.391890e+17                         make america great again!       56596   \n",
       "2  9.353400e+17                                   thank you rand!       42793   \n",
       "3  9.253890e+17                       thank you @luisriveramarin!       23521   \n",
       "4  8.997980e+17  join me live from fort myer in arlington, virg...      36009   \n",
       "\n",
       "   retweets                 date             date_new   date_part time_part  \\\n",
       "0     37189  2017-06-12 15:00:00  2017-06-12 23:00:00  2017-06-12  23:00:00   \n",
       "1     11433  2017-08-12 17:46:00  2017-08-13 01:46:00  2017-08-13  01:46:00   \n",
       "2      9125  2017-11-28 02:50:00  2017-11-28 10:50:00  2017-11-28  10:50:00   \n",
       "3      4574  2017-10-31 15:48:00  2017-10-31 23:48:00  2017-10-31  23:48:00   \n",
       "4      4891  2017-08-22 01:00:00  2017-08-22 09:00:00  2017-08-22  09:00:00   \n",
       "\n",
       "   hour  year  month                                    sentiment_score  \\\n",
       "0    23  2017      6  {'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'comp...   \n",
       "1     1  2017      8  {'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'comp...   \n",
       "2    10  2017     11  {'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...   \n",
       "3    23  2017     10  {'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...   \n",
       "4     9  2017      8  {'neg': 0.0, 'neu': 0.804, 'pos': 0.196, 'comp...   \n",
       "\n",
       "   tweet_length  compound                                       entity  \\\n",
       "0            25    0.6588                                           []   \n",
       "1            26    0.6588                                           []   \n",
       "2            16    0.4199                                     ['Rand']   \n",
       "3            28    0.4199                                           []   \n",
       "4            54    0.2960  ['Fort Myer', 'Arlington', 'Virginia', '➡']   \n",
       "\n",
       "                    entity_type  \\\n",
       "0                            []   \n",
       "1                            []   \n",
       "2                       ['ORG']   \n",
       "3                            []   \n",
       "4  ['GPE', 'GPE', 'GPE', 'ORG']   \n",
       "\n",
       "                                       cleaned_text2  \n",
       "0                          make america great again!  \n",
       "1                         make america great again!   \n",
       "2                                   thank you rand!   \n",
       "3                                       thank you !   \n",
       "4  join me live from fort myer in arlington, virg...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dow just crashes through 25,000. congrats! big cuts in unnecessary regulations continuing.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1:100,\"cleaned_text2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import string\n",
    "def give_emoji_free_text(text):\n",
    "    \"\"\"\n",
    "    Removes emoji's from tweets\n",
    "    Accepts:\n",
    "        Text (tweets)\n",
    "    Returns:\n",
    "        Text (emoji free tweets)\n",
    "    \"\"\"\n",
    "    emoji_list = [c for c in text if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    return clean_text\n",
    "\n",
    "def url_free_text(text):\n",
    "    '''\n",
    "    Cleans text from urls\n",
    "    '''\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the function above and get tweets free of emoji's\n",
    "call_emoji_free = lambda x: give_emoji_free_text(x)\n",
    "\n",
    "# Apply `call_emoji_free` which calls the function to remove all emoji's\n",
    "df['emoji_free_tweets'] = df['cleaned_text'].apply(call_emoji_free)\n",
    "\n",
    "#Create a new column with url free tweets\n",
    "df['url_free_tweets'] = df['emoji_free_tweets'].apply(url_free_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "for i in range(0,5088):\n",
    "    \n",
    "    df.loc[i,'cleaned_text2'] = re.sub('[%s]' % re.escape(string.punctuation), '',df.loc[i,'url_free_tweets'])\n",
    "    df.loc[i,'cleaned_text2'] = re.sub(\"@[A-Za-z0-9]+\",\"\",df.loc[i,'cleaned_text2'])\n",
    "    df.loc[i,'cleaned_text2']=re.sub('\\w*\\d\\w*', '', df.loc[i,'cleaned_text2'])\n",
    "    df.loc[i,'cleaned_text2'] = df.loc[i,'cleaned_text2'].strip(\"'\")\n",
    "    df.loc[i,'cleaned_text2']=df.loc[i,'cleaned_text2'].replace(\"#\", \"\")\n",
    "    df.loc[i,'cleaned_text2'].strip('\"') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50     i will be announcing the most dishonest amp co...\n",
       "51     “president trump has something now he didn’t h...\n",
       "52     such respect for the people of iran as they tr...\n",
       "53     melania and i are deeply saddened by the death...\n",
       "54     “some  us companies have responded to presiden...\n",
       "55     stock market had another good day but now that...\n",
       "56     many mostly democrat states refused to hand ov...\n",
       "57     as americans you need identification sometimes...\n",
       "58     with all of the failed “experts” weighing in d...\n",
       "59     so beautifulshow this picture to the nfl playe...\n",
       "60     dow just crashes through  congrats big cuts in...\n",
       "61     thank you to the great republican senators who...\n",
       "62                            making america great again\n",
       "63     i authorized zero access to white house actual...\n",
       "64     the fake news media barely mentions the fact t...\n",
       "65     dow goes from  on november   to  today for a n...\n",
       "66     well now that collusion with russia is proving...\n",
       "67     the mercer family recently dumped the leaker k...\n",
       "68                                        good idea rand\n",
       "69     michael wolff is a total loser who made up sto...\n",
       "70     the african american unemployment rate fell to...\n",
       "71     brian ross the reporter who made a fraudulent ...\n",
       "72     now that russian collusion after one year of i...\n",
       "73     actually throughout my life my two greatest as...\n",
       "74     to president of the united states on my first ...\n",
       "75     leaving camp david for the white house great m...\n",
       "76     i’ve had to put up with the fake news from the...\n",
       "77     jake tapper of fake news cnn just got destroye...\n",
       "78     the fake news awards those going to the most c...\n",
       "79     the stock market has been creating tremendous ...\n",
       "80     “his is turning out to be an enormously conseq...\n",
       "81     clinton in the wh doubling down on barack obam...\n",
       "82     african american unemployment is the lowest ev...\n",
       "83     can’t wait to be back in the amazing state of ...\n",
       "84     we have been working every day to deliver for ...\n",
       "85     in every decision we make we are honoring amer...\n",
       "86     we are fighting for our farmers for our countr...\n",
       "87     on behalf of the american people thank you to ...\n",
       "88     it was my great honor to sign hr  the “martin ...\n",
       "89                                    happy thanksgiving\n",
       "90                                                      \n",
       "91                                      fraudnewscnn fnn\n",
       "92                          will be another sean success\n",
       "93                   will be at the womens us open today\n",
       "94                                 big wins against isis\n",
       "95     blowout numbers on new jobs and separately ser...\n",
       "96                                       merry christmas\n",
       "97                                       merry christmas\n",
       "98     happy new year we are making america great aga...\n",
       "99     as our country rapidly grows stronger and smar...\n",
       "100    iran the number one state of sponsored terror ...\n",
       "Name: cleaned_text2, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[50:100,'cleaned_text2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it was my great honor to sign hr  the “martin luther king jr national historical park act” which redesignates the martin luther king junior national historic site in the state of georgia as the martin luther king jr national historical park'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not able to remove \"\"\n",
    "df.loc[88,'cleaned_text2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
