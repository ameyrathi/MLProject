{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\brgoh\\anaconda33\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from dateutil import parser\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets_stocks_combined_5mins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_datetime</th>\n",
       "      <th>date_part</th>\n",
       "      <th>time_part</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>datetime_5mins_after</th>\n",
       "      <th>price_5mins_after</th>\n",
       "      <th>eod_price</th>\n",
       "      <th>5mins_price_diff_abs</th>\n",
       "      <th>5mins_price_diff_perc</th>\n",
       "      <th>eod_price_diff_abs</th>\n",
       "      <th>eod_price_diff_perc</th>\n",
       "      <th>5mins_price_diff_perc_magnitude</th>\n",
       "      <th>eod_price_diff_perc_magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.353400e+17</td>\n",
       "      <td>thank you rand!</td>\n",
       "      <td>42793</td>\n",
       "      <td>9125</td>\n",
       "      <td>2017-11-28 02:50:00</td>\n",
       "      <td>2017-11-28 10:50:00</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>10:50:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>['ORG']</td>\n",
       "      <td>2017-11-28 10:55:00</td>\n",
       "      <td>261.085000</td>\n",
       "      <td>262.87</td>\n",
       "      <td>-0.015000</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.006779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.997980e+17</td>\n",
       "      <td>join me live from fort myer in arlington, virg...</td>\n",
       "      <td>36009</td>\n",
       "      <td>4891</td>\n",
       "      <td>2017-08-22 01:00:00</td>\n",
       "      <td>2017-08-22 09:00:00</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>['GPE', 'GPE', 'GPE', 'ORG']</td>\n",
       "      <td>2017-08-22 09:05:00</td>\n",
       "      <td>243.670000</td>\n",
       "      <td>245.44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>0.007264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.939700e+17</td>\n",
       "      <td>thank you nicole!</td>\n",
       "      <td>43367</td>\n",
       "      <td>8275</td>\n",
       "      <td>2017-05-08 23:01:00</td>\n",
       "      <td>2017-05-09 07:01:00</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>07:01:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>2017-05-09 07:06:00</td>\n",
       "      <td>239.920000</td>\n",
       "      <td>239.44</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>-0.435000</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.001813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.819770e+17</td>\n",
       "      <td>thank you to shawn steel for the nice words on .</td>\n",
       "      <td>50956</td>\n",
       "      <td>7465</td>\n",
       "      <td>2017-03-07 20:44:00</td>\n",
       "      <td>2017-03-08 04:44:00</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>04:44:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>2017-03-08 04:49:00</td>\n",
       "      <td>236.913333</td>\n",
       "      <td>236.56</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.320000</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.001351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.778460e+17</td>\n",
       "      <td>great night in iowa - special people. thank you!</td>\n",
       "      <td>56446</td>\n",
       "      <td>8039</td>\n",
       "      <td>2017-06-22 11:11:00</td>\n",
       "      <td>2017-06-22 19:11:00</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>19:11:00</td>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>['TIME', 'GPE']</td>\n",
       "      <td>2017-06-22 19:16:00</td>\n",
       "      <td>242.905000</td>\n",
       "      <td>242.84</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>9.990960e+17</td>\n",
       "      <td>if the person placed very early into my campai...</td>\n",
       "      <td>78529</td>\n",
       "      <td>20098</td>\n",
       "      <td>2018-05-23 01:13:00</td>\n",
       "      <td>2018-05-23 09:13:00</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>09:13:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>['ORG', 'GPE', 'PERSON', 'PERSON']</td>\n",
       "      <td>2018-05-23 09:18:00</td>\n",
       "      <td>271.100000</td>\n",
       "      <td>273.36</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.008560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>9.874600e+17</td>\n",
       "      <td>so general michael flynn’s life can be totally...</td>\n",
       "      <td>93569</td>\n",
       "      <td>25259</td>\n",
       "      <td>2018-04-20 10:34:00</td>\n",
       "      <td>2018-04-20 18:34:00</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>18:34:00</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>['PERSON', 'PERSON', 'PERSON', 'ORDINAL', 'GPE...</td>\n",
       "      <td>2018-04-20 18:39:00</td>\n",
       "      <td>266.866667</td>\n",
       "      <td>266.61</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>-0.210000</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>9.870960e+17</td>\n",
       "      <td>my thoughts, prayers and condolences are with ...</td>\n",
       "      <td>62645</td>\n",
       "      <td>16081</td>\n",
       "      <td>2018-04-19 22:30:00</td>\n",
       "      <td>2018-04-20 06:30:00</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>['CARDINAL', 'ORG', 'ORG', 'DATE', 'PERSON', '...</td>\n",
       "      <td>2018-04-20 06:35:00</td>\n",
       "      <td>268.715000</td>\n",
       "      <td>266.61</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>-2.010000</td>\n",
       "      <td>-0.007483</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.007483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>9.863570e+17</td>\n",
       "      <td>today’s court decision means that congress mus...</td>\n",
       "      <td>56749</td>\n",
       "      <td>12426</td>\n",
       "      <td>2018-04-17 21:34:00</td>\n",
       "      <td>2018-04-18 05:34:00</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>05:34:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>['DATE', 'ORG', 'ORG', 'ORG', 'ORG', 'ORG']</td>\n",
       "      <td>2018-04-18 05:39:00</td>\n",
       "      <td>270.600000</td>\n",
       "      <td>270.39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.210000</td>\n",
       "      <td>-0.000776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>9.791090e+17</td>\n",
       "      <td>i am pleased to announce that i intend to nomi...</td>\n",
       "      <td>66173</td>\n",
       "      <td>13399</td>\n",
       "      <td>2018-03-28 21:31:00</td>\n",
       "      <td>2018-03-29 05:31:00</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>05:31:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>['PERSON', 'ORG', 'ORG', 'ORG', 'PERSON', 'ORG...</td>\n",
       "      <td>2018-03-29 05:36:00</td>\n",
       "      <td>260.997143</td>\n",
       "      <td>263.15</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>2.167143</td>\n",
       "      <td>0.008304</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.008304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2669 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                       cleaned_text  \\\n",
       "0     9.353400e+17                                   thank you rand!    \n",
       "1     8.997980e+17  join me live from fort myer in arlington, virg...   \n",
       "2     8.939700e+17                                 thank you nicole!    \n",
       "3     8.819770e+17   thank you to shawn steel for the nice words on .   \n",
       "4     8.778460e+17   great night in iowa - special people. thank you!   \n",
       "...            ...                                                ...   \n",
       "2664  9.990960e+17  if the person placed very early into my campai...   \n",
       "2665  9.874600e+17  so general michael flynn’s life can be totally...   \n",
       "2666  9.870960e+17  my thoughts, prayers and condolences are with ...   \n",
       "2667  9.863570e+17  today’s court decision means that congress mus...   \n",
       "2668  9.791090e+17  i am pleased to announce that i intend to nomi...   \n",
       "\n",
       "      favorites  retweets                 date       tweet_datetime  \\\n",
       "0         42793      9125  2017-11-28 02:50:00  2017-11-28 10:50:00   \n",
       "1         36009      4891  2017-08-22 01:00:00  2017-08-22 09:00:00   \n",
       "2         43367      8275  2017-05-08 23:01:00  2017-05-09 07:01:00   \n",
       "3         50956      7465  2017-03-07 20:44:00  2017-03-08 04:44:00   \n",
       "4         56446      8039  2017-06-22 11:11:00  2017-06-22 19:11:00   \n",
       "...         ...       ...                  ...                  ...   \n",
       "2664      78529     20098  2018-05-23 01:13:00  2018-05-23 09:13:00   \n",
       "2665      93569     25259  2018-04-20 10:34:00  2018-04-20 18:34:00   \n",
       "2666      62645     16081  2018-04-19 22:30:00  2018-04-20 06:30:00   \n",
       "2667      56749     12426  2018-04-17 21:34:00  2018-04-18 05:34:00   \n",
       "2668      66173     13399  2018-03-28 21:31:00  2018-03-29 05:31:00   \n",
       "\n",
       "       date_part time_part  hour  year  ...  \\\n",
       "0     2017-11-28  10:50:00    10  2017  ...   \n",
       "1     2017-08-22  09:00:00     9  2017  ...   \n",
       "2     2017-05-09  07:01:00     7  2017  ...   \n",
       "3     2017-03-08  04:44:00     4  2017  ...   \n",
       "4     2017-06-22  19:11:00    19  2017  ...   \n",
       "...          ...       ...   ...   ...  ...   \n",
       "2664  2018-05-23  09:13:00     9  2018  ...   \n",
       "2665  2018-04-20  18:34:00    18  2018  ...   \n",
       "2666  2018-04-20  06:30:00     6  2018  ...   \n",
       "2667  2018-04-18  05:34:00     5  2018  ...   \n",
       "2668  2018-03-29  05:31:00     5  2018  ...   \n",
       "\n",
       "                                            entity_type datetime_5mins_after  \\\n",
       "0                                               ['ORG']  2017-11-28 10:55:00   \n",
       "1                          ['GPE', 'GPE', 'GPE', 'ORG']  2017-08-22 09:05:00   \n",
       "2                                            ['PERSON']  2017-05-09 07:06:00   \n",
       "3                                            ['PERSON']  2017-03-08 04:49:00   \n",
       "4                                       ['TIME', 'GPE']  2017-06-22 19:16:00   \n",
       "...                                                 ...                  ...   \n",
       "2664                 ['ORG', 'GPE', 'PERSON', 'PERSON']  2018-05-23 09:18:00   \n",
       "2665  ['PERSON', 'PERSON', 'PERSON', 'ORDINAL', 'GPE...  2018-04-20 18:39:00   \n",
       "2666  ['CARDINAL', 'ORG', 'ORG', 'DATE', 'PERSON', '...  2018-04-20 06:35:00   \n",
       "2667        ['DATE', 'ORG', 'ORG', 'ORG', 'ORG', 'ORG']  2018-04-18 05:39:00   \n",
       "2668  ['PERSON', 'ORG', 'ORG', 'ORG', 'PERSON', 'ORG...  2018-03-29 05:36:00   \n",
       "\n",
       "      price_5mins_after  eod_price 5mins_price_diff_abs 5mins_price_diff_perc  \\\n",
       "0            261.085000     262.87            -0.015000             -0.000057   \n",
       "1            243.670000     245.44             0.000000              0.000000   \n",
       "2            239.920000     239.44             0.045000              0.000188   \n",
       "3            236.913333     236.56             0.033333              0.000141   \n",
       "4            242.905000     242.84             0.025000              0.000103   \n",
       "...                 ...        ...                  ...                   ...   \n",
       "2664         271.100000     273.36             0.060000              0.000221   \n",
       "2665         266.866667     266.61             0.046667              0.000175   \n",
       "2666         268.715000     266.61             0.095000              0.000354   \n",
       "2667         270.600000     270.39             0.000000              0.000000   \n",
       "2668         260.997143     263.15             0.014286              0.000055   \n",
       "\n",
       "     eod_price_diff_abs  eod_price_diff_perc  5mins_price_diff_perc_magnitude  \\\n",
       "0              1.770000             0.006779                         0.000057   \n",
       "1              1.770000             0.007264                         0.000000   \n",
       "2             -0.435000            -0.001813                         0.000188   \n",
       "3             -0.320000            -0.001351                         0.000141   \n",
       "4             -0.040000            -0.000165                         0.000103   \n",
       "...                 ...                  ...                              ...   \n",
       "2664           2.320000             0.008560                         0.000221   \n",
       "2665          -0.210000            -0.000787                         0.000175   \n",
       "2666          -2.010000            -0.007483                         0.000354   \n",
       "2667          -0.210000            -0.000776                         0.000000   \n",
       "2668           2.167143             0.008304                         0.000055   \n",
       "\n",
       "      eod_price_diff_perc_magnitude  \n",
       "0                          0.006779  \n",
       "1                          0.007264  \n",
       "2                          0.001813  \n",
       "3                          0.001351  \n",
       "4                          0.000165  \n",
       "...                             ...  \n",
       "2664                       0.008560  \n",
       "2665                       0.000787  \n",
       "2666                       0.007483  \n",
       "2667                       0.000776  \n",
       "2668                       0.008304  \n",
       "\n",
       "[2669 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cleaned_text2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda33\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cleaned_text2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-77cbd1c67e0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cleaned_text2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'5mins_price_diff_perc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda33\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1760\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1762\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1763\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1764\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda33\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1272\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1273\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda33\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[1;31m# we have yielded a scalar ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda33\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1964\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1965\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1967\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda33\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda33\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3529\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3531\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda33\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda33\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cleaned_text2'"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, 'cleaned_text2']\n",
    "y = df.loc[:, '5mins_price_diff_perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_train:\n",
    "    corpus_list.append(i.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(corpus_list, min_count=1, size=100)\n",
    "pretrained_weights = word2vec_model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = [len(i) for i in corpus_list]\n",
    "longest_sentence_len = max(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_indices_padded(sentences, longest_sentence_len):\n",
    "    result = []\n",
    "    for sentence in sentences:\n",
    "        indices = []\n",
    "        sentence_splitted = sentence.split()\n",
    "        for word in sentence_splitted:\n",
    "            if word in word2vec_model.wv.vocab:\n",
    "                indices.append(word2vec_model.wv.vocab[word].index)\n",
    "        result.append(indices)\n",
    "    return keras.preprocessing.sequence.pad_sequences(result, maxlen=longest_sentence_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = sentence_to_indices_padded(X_train, longest_sentence_len)\n",
    "X_test_padded = sentence_to_indices_padded(X_test, longest_sentence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove/glove.twitter.27B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(nb_words=None)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_word_count = dict(tokenizer.word_counts)\n",
    "glove_sorted=dict(sorted(glove_word_count.items(), key=lambda x: x[1],reverse=True))\n",
    "print(glove_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2c = dict()\n",
    "for item in word2vec_model.wv.vocab:\n",
    "    w2c[item]=word2vec_model.wv.vocab[item].count\n",
    "w2c_sorted=dict(sorted(w2c.items(), key=lambda x: x[1],reverse=True))\n",
    "print(w2c_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_word_count = dict(tokenizer.word_counts)\n",
    "glove_sorted=dict(sorted(glove_word_count.items(), key=lambda x: x[1],reverse=True))\n",
    "print(glove_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_w2v = list(w2c.keys())\n",
    "words_gloves = list(glove_word_count.keys())\n",
    "extra = []\\\n",
    "for word in words_w2v:\n",
    "    if word not in words_gloves:\n",
    "        extra.append(word)\n",
    "print(extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "count = 0\n",
    "skipped_words = []\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        count += 1\n",
    "        skipped_words.append(word)\n",
    "vocab_size_glove, embedding_size_glove = embedding_matrix.shape\n",
    "print(vocab_size_glove)\n",
    "print(embedding_size)\n",
    "print(count)\n",
    "print(skipped_words)\n",
    "embedding_layer_glove = Embedding(len(word_index) + 1,\n",
    "                            100,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=longest_sentence_len,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM_model(pretrained_weights, longest_sentence_len):\n",
    "    vocab_size, embedding_size = pretrained_weights.shape\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=longest_sentence_len, dtype='int32'))\n",
    "    model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[pretrained_weights], trainable=False))  \n",
    "    model.add(layers.LSTM(4, return_sequences=True, name='LSTM1'))\n",
    "    model.add(layers.Dropout(0.25,name='Dropout1'))\n",
    "    model.add(layers.LSTM(4, return_sequences=False, name='LSTM2'))\n",
    "    model.add(layers.Dropout(0.25,name='Dropout2'))\n",
    "    model.add(layers.Dense(4,name='Dense',activation='sigmoid'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(1,activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_LSTM_model(pretrained_weights, longest_sentence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\\\"%d%m%Y %Hh%Mm\\\")\n",
    "\n",
    "checkpoint_filepath = f'./model_a_checkpoint/{dt_string}.h5'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose = 1,\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(X_train_padded, y_train, validation_split=0.2, epochs=50, callbacks=[model_checkpoint_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
