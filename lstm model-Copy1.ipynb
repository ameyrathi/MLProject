{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Amey/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/Amey/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/Amey/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/Amey/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/Amey/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/Amey/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/Amey/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from dateutil import parser\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Embedding\n",
    "import os\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2476 entries, 0 to 2475\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      2476 non-null   float64\n",
      " 1   text                    2426 non-null   object \n",
      " 2   favorites               2476 non-null   int64  \n",
      " 3   retweets                2476 non-null   int64  \n",
      " 4   date                    2476 non-null   object \n",
      " 5   tweet_datetime          2476 non-null   object \n",
      " 6   date_part               2476 non-null   object \n",
      " 7   time_part               2476 non-null   object \n",
      " 8   hour                    2476 non-null   int64  \n",
      " 9   year                    2476 non-null   int64  \n",
      " 10  month                   2476 non-null   int64  \n",
      " 11  datetime_30mins_after   2476 non-null   object \n",
      " 12  price_30mins_after      2476 non-null   float64\n",
      " 13  datetime_now            2476 non-null   object \n",
      " 14  price_now               2476 non-null   float64\n",
      " 15  30mins_price_diff_abs   2476 non-null   float64\n",
      " 16  30mins_price_diff_perc  2476 non-null   float64\n",
      "dtypes: float64(5), int64(5), object(7)\n",
      "memory usage: 329.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('tweets_stocks_combined_final.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_datetime</th>\n",
       "      <th>date_part</th>\n",
       "      <th>time_part</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>datetime_30mins_after</th>\n",
       "      <th>price_30mins_after</th>\n",
       "      <th>datetime_now</th>\n",
       "      <th>price_now</th>\n",
       "      <th>30mins_price_diff_abs</th>\n",
       "      <th>30mins_price_diff_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.353400e+17</td>\n",
       "      <td>thank you rand</td>\n",
       "      <td>42793</td>\n",
       "      <td>9125</td>\n",
       "      <td>2017-11-28 02:50:00</td>\n",
       "      <td>2017-11-28 10:50:00</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>10:50:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>2017-11-28 11:20:00</td>\n",
       "      <td>261.090000</td>\n",
       "      <td>2017-11-28 10:50:00</td>\n",
       "      <td>261.100000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.997980e+17</td>\n",
       "      <td>join me live from fort myer in arlington virginia</td>\n",
       "      <td>36009</td>\n",
       "      <td>4891</td>\n",
       "      <td>2017-08-22 01:00:00</td>\n",
       "      <td>2017-08-22 09:00:00</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-08-22 09:30:00</td>\n",
       "      <td>243.580000</td>\n",
       "      <td>2017-08-22 09:00:00</td>\n",
       "      <td>243.670000</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>-0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.939700e+17</td>\n",
       "      <td>thank you nicole</td>\n",
       "      <td>43367</td>\n",
       "      <td>8275</td>\n",
       "      <td>2017-05-08 23:01:00</td>\n",
       "      <td>2017-05-09 07:01:00</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>07:01:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-05-09 07:31:00</td>\n",
       "      <td>239.960000</td>\n",
       "      <td>2017-05-09 07:01:00</td>\n",
       "      <td>239.875000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.819770e+17</td>\n",
       "      <td>thank you to shawn steel for the nice words on</td>\n",
       "      <td>50956</td>\n",
       "      <td>7465</td>\n",
       "      <td>2017-03-07 20:44:00</td>\n",
       "      <td>2017-03-08 04:44:00</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>04:44:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-08 05:14:00</td>\n",
       "      <td>237.010000</td>\n",
       "      <td>2017-03-08 04:44:00</td>\n",
       "      <td>236.880000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.778460e+17</td>\n",
       "      <td>great night in iowa special people thank you</td>\n",
       "      <td>56446</td>\n",
       "      <td>8039</td>\n",
       "      <td>2017-06-22 11:11:00</td>\n",
       "      <td>2017-06-22 19:11:00</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>19:11:00</td>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-06-22 19:41:00</td>\n",
       "      <td>242.906667</td>\n",
       "      <td>2017-06-22 19:11:00</td>\n",
       "      <td>242.880000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>9.990960e+17</td>\n",
       "      <td>if the person placed very early into my campai...</td>\n",
       "      <td>78529</td>\n",
       "      <td>20098</td>\n",
       "      <td>2018-05-23 01:13:00</td>\n",
       "      <td>2018-05-23 09:13:00</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>09:13:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-05-23 09:43:00</td>\n",
       "      <td>271.520000</td>\n",
       "      <td>2018-05-23 09:13:00</td>\n",
       "      <td>271.040000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.001771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>9.874600e+17</td>\n",
       "      <td>so general michael flynns life can be totally ...</td>\n",
       "      <td>93569</td>\n",
       "      <td>25259</td>\n",
       "      <td>2018-04-20 10:34:00</td>\n",
       "      <td>2018-04-20 18:34:00</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>18:34:00</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-20 19:04:00</td>\n",
       "      <td>266.950000</td>\n",
       "      <td>2018-04-20 18:34:00</td>\n",
       "      <td>266.820000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.000487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>9.870960e+17</td>\n",
       "      <td>my thoughts prayers and condolences are with t...</td>\n",
       "      <td>62645</td>\n",
       "      <td>16081</td>\n",
       "      <td>2018-04-19 22:30:00</td>\n",
       "      <td>2018-04-20 06:30:00</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-20 07:00:00</td>\n",
       "      <td>269.240000</td>\n",
       "      <td>2018-04-20 06:30:00</td>\n",
       "      <td>268.620000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.002308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>9.863570e+17</td>\n",
       "      <td>todays court decision means that congress must...</td>\n",
       "      <td>56749</td>\n",
       "      <td>12426</td>\n",
       "      <td>2018-04-17 21:34:00</td>\n",
       "      <td>2018-04-18 05:34:00</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>05:34:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-18 06:04:00</td>\n",
       "      <td>270.552000</td>\n",
       "      <td>2018-04-18 05:34:00</td>\n",
       "      <td>270.600000</td>\n",
       "      <td>-0.048000</td>\n",
       "      <td>-0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>9.791090e+17</td>\n",
       "      <td>i am pleased to announce that i intend to nomi...</td>\n",
       "      <td>66173</td>\n",
       "      <td>13399</td>\n",
       "      <td>2018-03-28 21:31:00</td>\n",
       "      <td>2018-03-29 05:31:00</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>05:31:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-03-29 06:01:00</td>\n",
       "      <td>261.180000</td>\n",
       "      <td>2018-03-29 05:31:00</td>\n",
       "      <td>260.982857</td>\n",
       "      <td>0.197143</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2426 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text  \\\n",
       "0     9.353400e+17                                     thank you rand   \n",
       "1     8.997980e+17  join me live from fort myer in arlington virginia   \n",
       "2     8.939700e+17                                   thank you nicole   \n",
       "3     8.819770e+17     thank you to shawn steel for the nice words on   \n",
       "4     8.778460e+17       great night in iowa special people thank you   \n",
       "...            ...                                                ...   \n",
       "2471  9.990960e+17  if the person placed very early into my campai...   \n",
       "2472  9.874600e+17  so general michael flynns life can be totally ...   \n",
       "2473  9.870960e+17  my thoughts prayers and condolences are with t...   \n",
       "2474  9.863570e+17  todays court decision means that congress must...   \n",
       "2475  9.791090e+17  i am pleased to announce that i intend to nomi...   \n",
       "\n",
       "      favorites  retweets                 date       tweet_datetime  \\\n",
       "0         42793      9125  2017-11-28 02:50:00  2017-11-28 10:50:00   \n",
       "1         36009      4891  2017-08-22 01:00:00  2017-08-22 09:00:00   \n",
       "2         43367      8275  2017-05-08 23:01:00  2017-05-09 07:01:00   \n",
       "3         50956      7465  2017-03-07 20:44:00  2017-03-08 04:44:00   \n",
       "4         56446      8039  2017-06-22 11:11:00  2017-06-22 19:11:00   \n",
       "...         ...       ...                  ...                  ...   \n",
       "2471      78529     20098  2018-05-23 01:13:00  2018-05-23 09:13:00   \n",
       "2472      93569     25259  2018-04-20 10:34:00  2018-04-20 18:34:00   \n",
       "2473      62645     16081  2018-04-19 22:30:00  2018-04-20 06:30:00   \n",
       "2474      56749     12426  2018-04-17 21:34:00  2018-04-18 05:34:00   \n",
       "2475      66173     13399  2018-03-28 21:31:00  2018-03-29 05:31:00   \n",
       "\n",
       "       date_part time_part  hour  year  month datetime_30mins_after  \\\n",
       "0     2017-11-28  10:50:00    10  2017     11   2017-11-28 11:20:00   \n",
       "1     2017-08-22  09:00:00     9  2017      8   2017-08-22 09:30:00   \n",
       "2     2017-05-09  07:01:00     7  2017      5   2017-05-09 07:31:00   \n",
       "3     2017-03-08  04:44:00     4  2017      3   2017-03-08 05:14:00   \n",
       "4     2017-06-22  19:11:00    19  2017      6   2017-06-22 19:41:00   \n",
       "...          ...       ...   ...   ...    ...                   ...   \n",
       "2471  2018-05-23  09:13:00     9  2018      5   2018-05-23 09:43:00   \n",
       "2472  2018-04-20  18:34:00    18  2018      4   2018-04-20 19:04:00   \n",
       "2473  2018-04-20  06:30:00     6  2018      4   2018-04-20 07:00:00   \n",
       "2474  2018-04-18  05:34:00     5  2018      4   2018-04-18 06:04:00   \n",
       "2475  2018-03-29  05:31:00     5  2018      3   2018-03-29 06:01:00   \n",
       "\n",
       "      price_30mins_after         datetime_now   price_now  \\\n",
       "0             261.090000  2017-11-28 10:50:00  261.100000   \n",
       "1             243.580000  2017-08-22 09:00:00  243.670000   \n",
       "2             239.960000  2017-05-09 07:01:00  239.875000   \n",
       "3             237.010000  2017-03-08 04:44:00  236.880000   \n",
       "4             242.906667  2017-06-22 19:11:00  242.880000   \n",
       "...                  ...                  ...         ...   \n",
       "2471          271.520000  2018-05-23 09:13:00  271.040000   \n",
       "2472          266.950000  2018-04-20 18:34:00  266.820000   \n",
       "2473          269.240000  2018-04-20 06:30:00  268.620000   \n",
       "2474          270.552000  2018-04-18 05:34:00  270.600000   \n",
       "2475          261.180000  2018-03-29 05:31:00  260.982857   \n",
       "\n",
       "      30mins_price_diff_abs  30mins_price_diff_perc  \n",
       "0                 -0.010000               -0.000038  \n",
       "1                 -0.090000               -0.000369  \n",
       "2                  0.085000                0.000354  \n",
       "3                  0.130000                0.000549  \n",
       "4                  0.026667                0.000110  \n",
       "...                     ...                     ...  \n",
       "2471               0.480000                0.001771  \n",
       "2472               0.130000                0.000487  \n",
       "2473               0.620000                0.002308  \n",
       "2474              -0.048000               -0.000177  \n",
       "2475               0.197143                0.000755  \n",
       "\n",
       "[2426 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Amey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_a_df['30mins_price_diff_positive'] = model_a_df['30mins_price_diff_perc'].apply(lambda x: 1 if x >= 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_datetime</th>\n",
       "      <th>date_part</th>\n",
       "      <th>time_part</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>datetime_30mins_after</th>\n",
       "      <th>price_30mins_after</th>\n",
       "      <th>datetime_now</th>\n",
       "      <th>price_now</th>\n",
       "      <th>30mins_price_diff_abs</th>\n",
       "      <th>30mins_price_diff_perc</th>\n",
       "      <th>30mins_price_diff_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.353400e+17</td>\n",
       "      <td>thank you rand</td>\n",
       "      <td>42793</td>\n",
       "      <td>9125</td>\n",
       "      <td>2017-11-28 02:50:00</td>\n",
       "      <td>2017-11-28 10:50:00</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>10:50:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>2017-11-28 11:20:00</td>\n",
       "      <td>261.090000</td>\n",
       "      <td>2017-11-28 10:50:00</td>\n",
       "      <td>261.100000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.997980e+17</td>\n",
       "      <td>join me live from fort myer in arlington virginia</td>\n",
       "      <td>36009</td>\n",
       "      <td>4891</td>\n",
       "      <td>2017-08-22 01:00:00</td>\n",
       "      <td>2017-08-22 09:00:00</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-08-22 09:30:00</td>\n",
       "      <td>243.580000</td>\n",
       "      <td>2017-08-22 09:00:00</td>\n",
       "      <td>243.670000</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.939700e+17</td>\n",
       "      <td>thank you nicole</td>\n",
       "      <td>43367</td>\n",
       "      <td>8275</td>\n",
       "      <td>2017-05-08 23:01:00</td>\n",
       "      <td>2017-05-09 07:01:00</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>07:01:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-05-09 07:31:00</td>\n",
       "      <td>239.960000</td>\n",
       "      <td>2017-05-09 07:01:00</td>\n",
       "      <td>239.875000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.819770e+17</td>\n",
       "      <td>thank you to shawn steel for the nice words on</td>\n",
       "      <td>50956</td>\n",
       "      <td>7465</td>\n",
       "      <td>2017-03-07 20:44:00</td>\n",
       "      <td>2017-03-08 04:44:00</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>04:44:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-08 05:14:00</td>\n",
       "      <td>237.010000</td>\n",
       "      <td>2017-03-08 04:44:00</td>\n",
       "      <td>236.880000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.778460e+17</td>\n",
       "      <td>great night in iowa special people thank you</td>\n",
       "      <td>56446</td>\n",
       "      <td>8039</td>\n",
       "      <td>2017-06-22 11:11:00</td>\n",
       "      <td>2017-06-22 19:11:00</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>19:11:00</td>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-06-22 19:41:00</td>\n",
       "      <td>242.906667</td>\n",
       "      <td>2017-06-22 19:11:00</td>\n",
       "      <td>242.880000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>9.990960e+17</td>\n",
       "      <td>if the person placed very early into my campai...</td>\n",
       "      <td>78529</td>\n",
       "      <td>20098</td>\n",
       "      <td>2018-05-23 01:13:00</td>\n",
       "      <td>2018-05-23 09:13:00</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>09:13:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-05-23 09:43:00</td>\n",
       "      <td>271.520000</td>\n",
       "      <td>2018-05-23 09:13:00</td>\n",
       "      <td>271.040000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>9.874600e+17</td>\n",
       "      <td>so general michael flynns life can be totally ...</td>\n",
       "      <td>93569</td>\n",
       "      <td>25259</td>\n",
       "      <td>2018-04-20 10:34:00</td>\n",
       "      <td>2018-04-20 18:34:00</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>18:34:00</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-20 19:04:00</td>\n",
       "      <td>266.950000</td>\n",
       "      <td>2018-04-20 18:34:00</td>\n",
       "      <td>266.820000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>9.870960e+17</td>\n",
       "      <td>my thoughts prayers and condolences are with t...</td>\n",
       "      <td>62645</td>\n",
       "      <td>16081</td>\n",
       "      <td>2018-04-19 22:30:00</td>\n",
       "      <td>2018-04-20 06:30:00</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-20 07:00:00</td>\n",
       "      <td>269.240000</td>\n",
       "      <td>2018-04-20 06:30:00</td>\n",
       "      <td>268.620000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>9.863570e+17</td>\n",
       "      <td>todays court decision means that congress must...</td>\n",
       "      <td>56749</td>\n",
       "      <td>12426</td>\n",
       "      <td>2018-04-17 21:34:00</td>\n",
       "      <td>2018-04-18 05:34:00</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>05:34:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-18 06:04:00</td>\n",
       "      <td>270.552000</td>\n",
       "      <td>2018-04-18 05:34:00</td>\n",
       "      <td>270.600000</td>\n",
       "      <td>-0.048000</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>9.791090e+17</td>\n",
       "      <td>i am pleased to announce that i intend to nomi...</td>\n",
       "      <td>66173</td>\n",
       "      <td>13399</td>\n",
       "      <td>2018-03-28 21:31:00</td>\n",
       "      <td>2018-03-29 05:31:00</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>05:31:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-03-29 06:01:00</td>\n",
       "      <td>261.180000</td>\n",
       "      <td>2018-03-29 05:31:00</td>\n",
       "      <td>260.982857</td>\n",
       "      <td>0.197143</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2426 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text  \\\n",
       "0     9.353400e+17                                     thank you rand   \n",
       "1     8.997980e+17  join me live from fort myer in arlington virginia   \n",
       "2     8.939700e+17                                   thank you nicole   \n",
       "3     8.819770e+17     thank you to shawn steel for the nice words on   \n",
       "4     8.778460e+17       great night in iowa special people thank you   \n",
       "...            ...                                                ...   \n",
       "2471  9.990960e+17  if the person placed very early into my campai...   \n",
       "2472  9.874600e+17  so general michael flynns life can be totally ...   \n",
       "2473  9.870960e+17  my thoughts prayers and condolences are with t...   \n",
       "2474  9.863570e+17  todays court decision means that congress must...   \n",
       "2475  9.791090e+17  i am pleased to announce that i intend to nomi...   \n",
       "\n",
       "      favorites  retweets                 date       tweet_datetime  \\\n",
       "0         42793      9125  2017-11-28 02:50:00  2017-11-28 10:50:00   \n",
       "1         36009      4891  2017-08-22 01:00:00  2017-08-22 09:00:00   \n",
       "2         43367      8275  2017-05-08 23:01:00  2017-05-09 07:01:00   \n",
       "3         50956      7465  2017-03-07 20:44:00  2017-03-08 04:44:00   \n",
       "4         56446      8039  2017-06-22 11:11:00  2017-06-22 19:11:00   \n",
       "...         ...       ...                  ...                  ...   \n",
       "2471      78529     20098  2018-05-23 01:13:00  2018-05-23 09:13:00   \n",
       "2472      93569     25259  2018-04-20 10:34:00  2018-04-20 18:34:00   \n",
       "2473      62645     16081  2018-04-19 22:30:00  2018-04-20 06:30:00   \n",
       "2474      56749     12426  2018-04-17 21:34:00  2018-04-18 05:34:00   \n",
       "2475      66173     13399  2018-03-28 21:31:00  2018-03-29 05:31:00   \n",
       "\n",
       "       date_part time_part  hour  year  month datetime_30mins_after  \\\n",
       "0     2017-11-28  10:50:00    10  2017     11   2017-11-28 11:20:00   \n",
       "1     2017-08-22  09:00:00     9  2017      8   2017-08-22 09:30:00   \n",
       "2     2017-05-09  07:01:00     7  2017      5   2017-05-09 07:31:00   \n",
       "3     2017-03-08  04:44:00     4  2017      3   2017-03-08 05:14:00   \n",
       "4     2017-06-22  19:11:00    19  2017      6   2017-06-22 19:41:00   \n",
       "...          ...       ...   ...   ...    ...                   ...   \n",
       "2471  2018-05-23  09:13:00     9  2018      5   2018-05-23 09:43:00   \n",
       "2472  2018-04-20  18:34:00    18  2018      4   2018-04-20 19:04:00   \n",
       "2473  2018-04-20  06:30:00     6  2018      4   2018-04-20 07:00:00   \n",
       "2474  2018-04-18  05:34:00     5  2018      4   2018-04-18 06:04:00   \n",
       "2475  2018-03-29  05:31:00     5  2018      3   2018-03-29 06:01:00   \n",
       "\n",
       "      price_30mins_after         datetime_now   price_now  \\\n",
       "0             261.090000  2017-11-28 10:50:00  261.100000   \n",
       "1             243.580000  2017-08-22 09:00:00  243.670000   \n",
       "2             239.960000  2017-05-09 07:01:00  239.875000   \n",
       "3             237.010000  2017-03-08 04:44:00  236.880000   \n",
       "4             242.906667  2017-06-22 19:11:00  242.880000   \n",
       "...                  ...                  ...         ...   \n",
       "2471          271.520000  2018-05-23 09:13:00  271.040000   \n",
       "2472          266.950000  2018-04-20 18:34:00  266.820000   \n",
       "2473          269.240000  2018-04-20 06:30:00  268.620000   \n",
       "2474          270.552000  2018-04-18 05:34:00  270.600000   \n",
       "2475          261.180000  2018-03-29 05:31:00  260.982857   \n",
       "\n",
       "      30mins_price_diff_abs  30mins_price_diff_perc  \\\n",
       "0                 -0.010000               -0.000038   \n",
       "1                 -0.090000               -0.000369   \n",
       "2                  0.085000                0.000354   \n",
       "3                  0.130000                0.000549   \n",
       "4                  0.026667                0.000110   \n",
       "...                     ...                     ...   \n",
       "2471               0.480000                0.001771   \n",
       "2472               0.130000                0.000487   \n",
       "2473               0.620000                0.002308   \n",
       "2474              -0.048000               -0.000177   \n",
       "2475               0.197143                0.000755   \n",
       "\n",
       "      30mins_price_diff_positive  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              1  \n",
       "3                              1  \n",
       "4                              1  \n",
       "...                          ...  \n",
       "2471                           1  \n",
       "2472                           1  \n",
       "2473                           1  \n",
       "2474                           0  \n",
       "2475                           1  \n",
       "\n",
       "[2426 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model A (only word vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model_a_df['text']\n",
    "y = model_a_df['30mins_price_diff_positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_corpus_list = []\n",
    "\n",
    "for i in model_a_X_train:\n",
    "    model_a_corpus_list.append(i.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_word2vec_model = Word2Vec(model_a_corpus_list, min_count=1, size=100)\n",
    "model_a_pretrained_weights = model_a_word2vec_model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_num_words = [len(i) for i in model_a_corpus_list]\n",
    "model_a_longest_sentence_len = max(model_a_num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove/glove.twitter.27B.50d.txt', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5039 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "#text to integers\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "longest_sentence_len = 30\n",
    "x_train_padded = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=longest_sentence_len, padding='post')\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set(word_index.keys())\n",
    "def prepare_test_x_glove(x):\n",
    "    \n",
    "    global unique_words\n",
    "    global word_index\n",
    "    global longest_sentence_len\n",
    "    result = []\n",
    "    \n",
    "    for tweet in x:\n",
    "        indices = []\n",
    "        for word in tweet.split():\n",
    "            if word in unique_words:\n",
    "                indices.append(word_index[word])\n",
    "            else:\n",
    "                indices.append(0)\n",
    "            \n",
    "        result.append(indices)\n",
    "    return keras.preprocessing.sequence.pad_sequences(result, maxlen=longest_sentence_len, padding='post')\n",
    "\n",
    "x_test_padded = prepare_test_x_glove(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.438769230769232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 318,   23,  304, ...,    0,    0,    0],\n",
       "       [ 103,  814,    2, ...,    0,    0,    0],\n",
       "       [   1,  210,    0, ...,    2, 1483,  438],\n",
       "       ...,\n",
       "       [1221,   54,  400, ...,    0,    0,    0],\n",
       "       [   0,   12,   16, ...,   44,   42,    5],\n",
       "       [  37,    9,    2, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean([len(sequence) for sequence in sequences]))\n",
    "x_test_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "embedding_layer_glove = Embedding(vocab_size,\n",
    "                            50,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=longest_sentence_len,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \n",
    "    global embedding_layer_glove\n",
    "    vocab_size, embedding_size = pretrained_weights.shape\n",
    "    model = keras.Sequential()\n",
    "    # model.add(layers.Input(shape=longest_sentence_len, dtype='int32'))\n",
    "    model.add(embedding_layer_glove)\n",
    "    # model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[pretrained_weights], trainable=False))  \n",
    "    model.add(layers.LSTM(4, return_sequences=True, name='LSTM1'))\n",
    "    model.add(layers.Dropout(0.25,name='Dropout1'))\n",
    "    model.add(layers.LSTM(4, return_sequences=False, name='LSTM2'))\n",
    "    model.add(layers.Dropout(0.25,name='Dropout2'))\n",
    "    model.add(layers.Dense(4,name='Dense',activation='tanh'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(2,activation='Softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model A (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_classification():\n",
    "    global embedding_layer_glove\n",
    "#     vocab_size, embedding_size = pretrained_weights.shape\n",
    "    model = keras.Sequential()\n",
    "    # model.add(layers.Input(shape=longest_sentence_len, dtype='int32'))\n",
    "    model.add(embedding_layer_glove)\n",
    "    # model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[pretrained_weights], trainable=False))  \n",
    "    model.add(layers.LSTM(4, return_sequences=True, name='LSTM1'))\n",
    "    model.add(layers.Dropout(0.25,name='Dropout1'))\n",
    "    model.add(layers.LSTM(4, return_sequences=False, name='LSTM2'))\n",
    "    model.add(layers.Dropout(0.25,name='Dropout2'))\n",
    "#     model.add(layers.Dense(4,name='Dense',activation='sigmoid'))\n",
    "#     model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 50)            252000    \n",
      "_________________________________________________________________\n",
      "LSTM1 (LSTM)                 (None, 30, 4)             880       \n",
      "_________________________________________________________________\n",
      "Dropout1 (Dropout)           (None, 30, 4)             0         \n",
      "_________________________________________________________________\n",
      "LSTM2 (LSTM)                 (None, 4)                 144       \n",
      "_________________________________________________________________\n",
      "Dropout2 (Dropout)           (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 253,029\n",
      "Trainable params: 1,029\n",
      "Non-trainable params: 252,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = create_model_classification()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "classification_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1300 samples, validate on 325 samples\n",
      "Epoch 1/20\n",
      "1300/1300 [==============================] - 7s 6ms/sample - loss: 0.6930 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5262\n",
      "Epoch 2/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6900 - accuracy: 0.5554 - val_loss: 0.6920 - val_accuracy: 0.5323\n",
      "Epoch 3/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6887 - accuracy: 0.5631 - val_loss: 0.6921 - val_accuracy: 0.5323\n",
      "Epoch 4/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6877 - accuracy: 0.5569 - val_loss: 0.6931 - val_accuracy: 0.5292\n",
      "Epoch 5/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6867 - accuracy: 0.5615 - val_loss: 0.6950 - val_accuracy: 0.5231\n",
      "Epoch 6/20\n",
      "1300/1300 [==============================] - 1s 1ms/sample - loss: 0.6859 - accuracy: 0.5708 - val_loss: 0.6968 - val_accuracy: 0.5231\n",
      "Epoch 7/20\n",
      "1300/1300 [==============================] - 1s 1ms/sample - loss: 0.6834 - accuracy: 0.5631 - val_loss: 0.6985 - val_accuracy: 0.5200\n",
      "Epoch 8/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6820 - accuracy: 0.5746 - val_loss: 0.7016 - val_accuracy: 0.5138\n",
      "Epoch 9/20\n",
      "1300/1300 [==============================] - 1s 1ms/sample - loss: 0.6802 - accuracy: 0.5777 - val_loss: 0.7041 - val_accuracy: 0.5200\n",
      "Epoch 10/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6784 - accuracy: 0.5792 - val_loss: 0.7099 - val_accuracy: 0.4646\n",
      "Epoch 11/20\n",
      "1300/1300 [==============================] - 1s 1ms/sample - loss: 0.6785 - accuracy: 0.5846 - val_loss: 0.7063 - val_accuracy: 0.5015\n",
      "Epoch 12/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6772 - accuracy: 0.5892 - val_loss: 0.7093 - val_accuracy: 0.4985\n",
      "Epoch 13/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6761 - accuracy: 0.5785 - val_loss: 0.7107 - val_accuracy: 0.4954\n",
      "Epoch 14/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6744 - accuracy: 0.5877 - val_loss: 0.7081 - val_accuracy: 0.5138\n",
      "Epoch 15/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6687 - accuracy: 0.6031 - val_loss: 0.7219 - val_accuracy: 0.4492\n",
      "Epoch 16/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6750 - accuracy: 0.5846 - val_loss: 0.7133 - val_accuracy: 0.4892\n",
      "Epoch 17/20\n",
      "1300/1300 [==============================] - 2s 1ms/sample - loss: 0.6707 - accuracy: 0.6000 - val_loss: 0.7109 - val_accuracy: 0.4954\n",
      "Epoch 18/20\n",
      "1300/1300 [==============================] - 1s 1ms/sample - loss: 0.6690 - accuracy: 0.6154 - val_loss: 0.7185 - val_accuracy: 0.4738\n",
      "Epoch 19/20\n",
      "1300/1300 [==============================] - 1s 1ms/sample - loss: 0.6656 - accuracy: 0.6123 - val_loss: 0.7178 - val_accuracy: 0.4923\n",
      "Epoch 20/20\n",
      "1300/1300 [==============================] - 1s 1ms/sample - loss: 0.6634 - accuracy: 0.6115 - val_loss: 0.7218 - val_accuracy: 0.4892\n",
      "801/801 [==============================] - 0s 231us/sample - loss: 0.6874 - accuracy: 0.5705\n",
      "0.6874320396174504\n",
      "0.57053685\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d%m%Y %H%Mh\")\n",
    "\n",
    "# checkpoint_filepath = f'./model_a_checkpoint/classification {dt_string}.h5'\n",
    "# model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=checkpoint_filepath,\n",
    "#     save_weights_only=True,\n",
    "#     monitor='val_loss',\n",
    "#     mode='min',\n",
    "#     verbose = 1,\n",
    "#     save_best_only=True) \n",
    "\n",
    "classification_model.fit(x_train_padded, y_train, validation_split=0.2, epochs=20,verbose=1)\n",
    "test_loss, test_acc = classification_model.evaluate(x_test_padded, y_test,verbose=1)\n",
    "print(test_loss)\n",
    "print(test_acc)\n",
    "\n",
    "# classification_history = classification_model.fit(x_train_padded, y_train, validation_split=0.2, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_pred = classification_model.predict(x_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15714bf98>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification_loaded = create_model_classification()\n",
    "# classification_loaded.load_weights(checkpoint_filepath)\n",
    "# classification_loaded.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# classification_pred = classification_loaded.predict(x_test_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.argmax(i) for i in classification_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPYUlEQVR4nO3dbYxc51nG8f+FTU1fFDVRNsHddbABt8WOQG1XJlAJVQSwUas6XyI5otQqkSwqF1oEam36IZ8sBYF4qSCRrDbUEVUsqxTFaklpMFQVIq276VviuG6WOrW3duMt5SWA5NbuzYc5iNFm1uud2cw2fv4/aXXOuc9zzrlHWl179MyZ2VQVkqQ2/NBqNyBJGh9DX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIWtXu4Gl3HjjjbVx48bVbkOSXlQef/zxb1fVxML6D3zob9y4kZmZmdVuQ5JeVJJ8Y1Dd6R1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhqyZOgneSDJhSRPDtj3e0kqyY19tf1JZpOcSrK9r/6GJE90+z6QJCv3MiRJV+NqPpz1YeDPgQf7i0k2AL8MnOmrbQF2AVuBVwF/n+TVVXUZuB/YA3wW+FtgB/DI6C/hB8PGfZ9Y7RauGc/c++bVbkG6Zi15p19VnwG+M2DXnwDvBfr/9dZO4HBVXayq08AssC3JeuC6qnqsev+q60HgjlGblyQtz1Bz+kneCnyzqr68YNckcLZve66rTXbrC+uSpDFa9nfvJHkZ8H7gVwbtHlCrK9QXu8YeelNB3HLLLcttUZK0iGHu9H8C2AR8OckzwBTwhSQ/Su8OfkPf2CngXFefGlAfqKoOVtV0VU1PTDzvS+IkSUNaduhX1RNVdVNVbayqjfQC/fVV9S3gKLArybokm4DNwPGqOg88l+S27qmdtwMPr9zLkCRdjat5ZPMh4DHgNUnmkty92NiqOgEcAZ4CPgns7Z7cAXgn8EF6b+7+C9fQkzuS9GKx5Jx+Vd21xP6NC7YPAAcGjJsBbl1mf5KkFeQnciWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1JAlQz/JA0kuJHmyr/aHSb6a5CtJ/ibJK/v27U8ym+RUku199TckeaLb94EkWfFXI0m6oqu50/8wsGNB7VHg1qr6aeBrwH6AJFuAXcDW7pj7kqzpjrkf2ANs7n4WnlOS9AJbMvSr6jPAdxbUPlVVl7rNzwJT3fpO4HBVXayq08AssC3JeuC6qnqsqgp4ELhjhV6DJOkqrcSc/m8Aj3Trk8DZvn1zXW2yW19YlySN0Uihn+T9wCXgI/9XGjCsrlBf7Lx7kswkmZmfnx+lRUlSn6FDP8lu4C3Ar3VTNtC7g9/QN2wKONfVpwbUB6qqg1U1XVXTExMTw7YoSVpgqNBPsgN4H/DWqvqfvl1HgV1J1iXZRO8N2+NVdR54Lslt3VM7bwceHrF3SdIyrV1qQJKHgDcBNyaZA+6h97TOOuDR7snLz1bVb1bViSRHgKfoTfvsrarL3aneSe9JoJfSew/gESRJY7Vk6FfVXQPKH7rC+APAgQH1GeDWZXUnSVpRfiJXkhpi6EtSQwx9SWrIknP6kl7cNu77xGq3cE155t43r3YLI/FOX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkCVDP8kDSS4kebKvdkOSR5M83S2v79u3P8lsklNJtvfV35DkiW7fB5Jk5V+OJOlKruZO/8PAjgW1fcCxqtoMHOu2SbIF2AVs7Y65L8ma7pj7gT3A5u5n4TklSS+wJUO/qj4DfGdBeSdwqFs/BNzRVz9cVRer6jQwC2xLsh64rqoeq6oCHuw7RpI0JsPO6d9cVecBuuVNXX0SONs3bq6rTXbrC+uSpDFa6TdyB83T1xXqg0+S7Ekyk2Rmfn5+xZqTpNYNG/rPdlM2dMsLXX0O2NA3bgo419WnBtQHqqqDVTVdVdMTExNDtihJWmjY0D8K7O7WdwMP99V3JVmXZBO9N2yPd1NAzyW5rXtq5+19x0iSxmTtUgOSPAS8CbgxyRxwD3AvcCTJ3cAZ4E6AqjqR5AjwFHAJ2FtVl7tTvZPek0AvBR7pfiRJY7Rk6FfVXYvsun2R8QeAAwPqM8Cty+pOkrSi/ESuJDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkNGCv0kv5PkRJInkzyU5EeS3JDk0SRPd8vr+8bvTzKb5FSS7aO3L0lajqFDP8kk8NvAdFXdCqwBdgH7gGNVtRk41m2TZEu3fyuwA7gvyZrR2pckLceo0ztrgZcmWQu8DDgH7AQOdfsPAXd06zuBw1V1sapOA7PAthGvL0lahqFDv6q+CfwRcAY4D/xHVX0KuLmqzndjzgM3dYdMAmf7TjHX1SRJYzLK9M719O7eNwGvAl6e5G1XOmRArRY5954kM0lm5ufnh21RkrTAKNM7vwScrqr5qvoe8DHg54Fnk6wH6JYXuvFzwIa+46foTQc9T1UdrKrpqpqemJgYoUVJUr9RQv8McFuSlyUJcDtwEjgK7O7G7AYe7taPAruSrEuyCdgMHB/h+pKkZVo77IFV9bkkHwW+AFwCvggcBF4BHElyN70/DHd2408kOQI81Y3fW1WXR+xfkrQMQ4c+QFXdA9yzoHyR3l3/oPEHgAOjXFOSNDw/kStJDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIaMFPpJXpnko0m+muRkkp9LckOSR5M83S2v7xu/P8lsklNJto/eviRpOUa90/8z4JNV9VrgZ4CTwD7gWFVtBo512yTZAuwCtgI7gPuSrBnx+pKkZRg69JNcB/wC8CGAqvpuVf07sBM41A07BNzRre8EDlfVxao6DcwC24a9viRp+Ua50/9xYB74yyRfTPLBJC8Hbq6q8wDd8qZu/CRwtu/4ua4mSRqTUUJ/LfB64P6qeh3w33RTOYvIgFoNHJjsSTKTZGZ+fn6EFiVJ/UYJ/Tlgrqo+121/lN4fgWeTrAfolhf6xm/oO34KODfoxFV1sKqmq2p6YmJihBYlSf2GDv2q+hZwNslrutLtwFPAUWB3V9sNPNytHwV2JVmXZBOwGTg+7PUlScu3dsTjfwv4SJKXAF8H3kHvD8mRJHcDZ4A7AarqRJIj9P4wXAL2VtXlEa8vSVqGkUK/qr4ETA/Ydfsi4w8AB0a5piRpeH4iV5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDRk59JOsSfLFJB/vtm9I8miSp7vl9X1j9yeZTXIqyfZRry1JWp6VuNN/N3Cyb3sfcKyqNgPHum2SbAF2AVuBHcB9SdaswPUlSVdppNBPMgW8GfhgX3kncKhbPwTc0Vc/XFUXq+o0MAtsG+X6kqTlGfVO/0+B9wLf76vdXFXnAbrlTV19EjjbN26uq0mSxmTo0E/yFuBCVT1+tYcMqNUi596TZCbJzPz8/LAtSpIWGOVO/43AW5M8AxwGfjHJXwHPJlkP0C0vdOPngA19x08B5waduKoOVtV0VU1PTEyM0KIkqd/QoV9V+6tqqqo20nuD9h+q6m3AUWB3N2w38HC3fhTYlWRdkk3AZuD40J1LkpZt7QtwznuBI0nuBs4AdwJU1YkkR4CngEvA3qq6/AJcX5K0iBUJ/ar6NPDpbv1fgdsXGXcAOLAS15QkLZ+fyJWkhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkOGDv0kG5L8Y5KTSU4keXdXvyHJo0me7pbX9x2zP8lsklNJtq/EC5AkXb1R7vQvAb9bVT8F3AbsTbIF2Accq6rNwLFum27fLmArsAO4L8maUZqXJC3P0KFfVeer6gvd+nPASWAS2Akc6oYdAu7o1ncCh6vqYlWdBmaBbcNeX5K0fCsyp59kI/A64HPAzVV1Hnp/GICbumGTwNm+w+a6miRpTEYO/SSvAP4aeE9V/eeVhg6o1SLn3JNkJsnM/Pz8qC1KkjojhX6SH6YX+B+pqo915WeTrO/2rwcudPU5YEPf4VPAuUHnraqDVTVdVdMTExOjtChJ6jPK0zsBPgScrKo/7tt1FNjdre8GHu6r70qyLskmYDNwfNjrS5KWb+0Ix74R+HXgiSRf6mq/D9wLHElyN3AGuBOgqk4kOQI8Re/Jn71VdXmE60uSlmno0K+qf2LwPD3A7YsccwA4MOw1JUmj8RO5ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0Ze+gn2ZHkVJLZJPvGfX1JatlYQz/JGuAvgF8FtgB3Jdkyzh4kqWXjvtPfBsxW1der6rvAYWDnmHuQpGatHfP1JoGzfdtzwM8uHJRkD7Cn2/yvJKfG0FsLbgS+vdpNLCV/sNodaJX4+7myfmxQcdyhnwG1el6h6iBw8IVvpy1JZqpqerX7kAbx93M8xj29Mwds6NueAs6NuQdJata4Q//zwOYkm5K8BNgFHB1zD5LUrLFO71TVpSTvAv4OWAM8UFUnxtlD45wy0w8yfz/HIFXPm1KXJF2j/ESuJDXE0Jekhhj6ktSQcT+nL0kkeS29T+NP0vuszjngaFWdXNXGGuCdfqOSvGO1e1CbkryP3lewBDhO71HuAA/5JYwvPJ/eaVSSM1V1y2r3ofYk+Rqwtaq+t6D+EuBEVW1enc7a4PTONSzJVxbbBdw8zl6kPt8HXgV8Y0F9fbdPLyBD/9p2M7Ad+LcF9QD/PP52JADeAxxL8jT//wWMtwA/CbxrtZpqhaF/bfs48Iqq+tLCHUk+PfZuJKCqPpnk1fS+an2S3k3IHPD5qrq8qs01wDl9SWqIT+9IUkMMfUlqiKEvSQ0x9CWpIYa+JDXkfwHj4d0MmiaUtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(classification_y).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model B (word vectors + price history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b_df = df.dropna(subset=['cleaned_text', 'prev_60mins_prices'])\n",
    "\n",
    "model_b_X = model_b_df.loc[:, ['cleaned_text_2', 'prev_60mins_prices']]\n",
    "model_b_y = model_b_df.loc[:, '60mins_price_diff_perc']\n",
    "\n",
    "model_b_X_train, model_b_X_test, model_b_y_train, model_b_y_test = train_test_split(model_b_X, model_b_y, test_size=0.33, random_state=42)\n",
    "\n",
    "model_b_X_train_text = model_b_X_train.iloc[:, 0]\n",
    "model_b_X_train_price_history = model_b_X_train.iloc[:, 1].apply(lambda x: split(strip()))\n",
    "model_b_X_test_text = model_b_X_test.iloc[:, 0]\n",
    "model_b_X_test_price_history = model_b_X_test.iloc[:, 1]\n",
    "                           \n",
    "model_b_corpus_list = []\n",
    "\n",
    "for i in model_b_X_train_text:\n",
    "    model_b_corpus_list.append(i.split())\n",
    "    \n",
    "model_b_word2vec_model = Word2Vec(model_b_corpus_list, min_count=1, size=100)\n",
    "model_b_pretrained_weights = model_b_word2vec_model.wv.vectors\n",
    "\n",
    "model_b_num_words = [len(i) for i in model_b_corpus_list]\n",
    "model_b_longest_sentence_len = max(model_b_num_words)\n",
    "\n",
    "model_b_X_train_padded = sentence_to_indices_padded(model_b_X_train_text, model_b_longest_sentence_len)\n",
    "model_b_X_test_padded = sentence_to_indices_padded(model_b_X_test_text, model_b_longest_sentence_len)\n",
    "\n",
    "model_b_X_train_input = [model_b_X_train_padded, np.array(model_b_X_train_price_history)]\n",
    "model_b_X_test_input = [model_b_X_test_padded, model_b_X_test_price_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.array(model_b_X_train_input[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_b(pretrained_weights, longest_sentence_len, price_history_shape):\n",
    "    vocab_size, embedding_size = pretrained_weights.shape\n",
    "    \n",
    "    # word vectors model\n",
    "    model1_input = layers.Input(shape=longest_sentence_len, dtype='int32', name='sentence_index_input')\n",
    "    model1 = layers.Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[pretrained_weights], trainable=False)(model1_input)  \n",
    "    model1 = layers.LSTM(4, return_sequences=True, name='model1_LSTM1')(model1)\n",
    "    model1 = layers.Dropout(0.25,name='model1_dropout1')(model1)\n",
    "    model1 = layers.LSTM(4, return_sequences=False, name='model1_LSTM2')(model1)\n",
    "    model1 = layers.Dropout(0.25,name='model1_dropout2')(model1)\n",
    "    \n",
    "    # price history model\n",
    "    model2_input = layers.Input(shape=price_history_shape, dtype='float32', name='price_history_input')\n",
    "    model2 = layers.LSTM(4, return_sequences=True, name='model2_LSTM1')(model2_input)\n",
    "    model2 = layers.Dropout(0.25,name='model2_dropout1')(model2)\n",
    "    model2 = layers.LSTM(4, return_sequences=False, name='model2_LSTM2')(model2)\n",
    "    model2 = layers.Dropout(0.25,name='model2_dropout2')(model2)\n",
    "    \n",
    "    model_concat = layers.concatenate([model1, model2])\n",
    "    model_concat = layers.Dense(4,name='Dense',activation='relu')(model_concat)\n",
    "    model_concat = layers.Dropout(0.1)(model_concat)\n",
    "    model_concat = layers.Dense(1,activation='linear')(model_concat)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[model1_input, model2_input], outputs = model_concat)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = create_model_b(model_b_pretrained_weights, model_b_longest_sentence_len, (30,1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d%m%Y %H%Mh\")\n",
    "\n",
    "checkpoint_filepath = f'./model_b_checkpoint/{dt_string}.h5'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose = 1,\n",
    "    save_best_only=True) \n",
    "\n",
    "model_b.fit(model_b_X_train_input, model_b_y_train, validation_split=0.2, epochs=50, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b_X_train_input[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
