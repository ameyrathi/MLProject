{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 mins change in stock price results (df2) (can ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for getting the price change (price before tweet and price after the tweet) #5mins interval one\n",
    "df2 = pd.read_csv(\"tweets_stocks_combined_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5312, 18)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2646 entries, 0 to 2696\n",
      "Data columns (total 19 columns):\n",
      "id                       2646 non-null float64\n",
      "text                     2646 non-null object\n",
      "favorites                2646 non-null int64\n",
      "retweets                 2646 non-null int64\n",
      "date                     2646 non-null object\n",
      "tweet_datetime           2646 non-null object\n",
      "date_part                2646 non-null object\n",
      "time_part                2646 non-null object\n",
      "hour                     2646 non-null int64\n",
      "year                     2646 non-null int64\n",
      "month                    2646 non-null int64\n",
      "topic                    2646 non-null int64\n",
      "compound                 2646 non-null float64\n",
      "datetime_5mins_after     2646 non-null object\n",
      "price_5mins_after        2646 non-null float64\n",
      "price_now                2646 non-null float64\n",
      "5mins_price_diff_abs     2646 non-null float64\n",
      "5mins_price_diff_perc    2646 non-null float64\n",
      "y_label                  2646 non-null int64\n",
      "dtypes: float64(6), int64(7), object(6)\n",
      "memory usage: 413.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abs_diff has been calculated as price_5mins after - price now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7299999999999611"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df2.loc[:,\"5mins_price_diff_abs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6399999999999864"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df2.loc[:,\"5mins_price_diff_abs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list of values for the y label for each row\n",
    "target_value=[]\n",
    "for i in range(0,2697):\n",
    "    \n",
    "    if (df2.loc[i,\"5mins_price_diff_abs\"]>0)==True:\n",
    "        target_value.append(1)\n",
    "        i+=1\n",
    "    elif (df2.loc[i,\"5mins_price_diff_abs\"]<0)==True:\n",
    "        target_value.append(-1)\n",
    "        i+=1\n",
    "    else:\n",
    "        target_value.append(0)\n",
    "        i+=1\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for the y_label \n",
    "df2.loc[:,'y_label'] = target_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check if correctly classified\n",
    "#df2[df2['y_label']==-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1366 1207\n"
     ]
    }
   ],
   "source": [
    "#checking if correctly classified\n",
    "counter1=0\n",
    "counter2=0\n",
    "for i in range(0,2697):\n",
    "    if (df2.loc[i,\"5mins_price_diff_abs\"]>0)==True:\n",
    "        counter1+=1\n",
    "    elif (df2.loc[i,\"5mins_price_diff_abs\"]<0)==True:\n",
    "        counter2+=1\n",
    "    i+=1\n",
    "print(counter1, counter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2754, 12)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2697, 19)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2697 entries, 0 to 2696\n",
      "Data columns (total 19 columns):\n",
      "id                       2697 non-null float64\n",
      "text                     2646 non-null object\n",
      "favorites                2697 non-null int64\n",
      "retweets                 2697 non-null int64\n",
      "date                     2697 non-null object\n",
      "tweet_datetime           2697 non-null object\n",
      "date_part                2697 non-null object\n",
      "time_part                2697 non-null object\n",
      "hour                     2697 non-null int64\n",
      "year                     2697 non-null int64\n",
      "month                    2697 non-null int64\n",
      "topic                    2697 non-null int64\n",
      "compound                 2697 non-null float64\n",
      "datetime_5mins_after     2697 non-null object\n",
      "price_5mins_after        2697 non-null float64\n",
      "price_now                2697 non-null float64\n",
      "5mins_price_diff_abs     2697 non-null float64\n",
      "5mins_price_diff_perc    2697 non-null float64\n",
      "y_label                  2697 non-null int64\n",
      "dtypes: float64(6), int64(7), object(6)\n",
      "memory usage: 400.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_datetime</th>\n",
       "      <th>date_part</th>\n",
       "      <th>time_part</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>compound</th>\n",
       "      <th>datetime_5mins_after</th>\n",
       "      <th>price_5mins_after</th>\n",
       "      <th>price_now</th>\n",
       "      <th>5mins_price_diff_abs</th>\n",
       "      <th>5mins_price_diff_perc</th>\n",
       "      <th>y_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.353400e+17</td>\n",
       "      <td>thank rand</td>\n",
       "      <td>42793</td>\n",
       "      <td>9125</td>\n",
       "      <td>2017-11-28 02:50:00</td>\n",
       "      <td>2017-11-28 10:50:00</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>10:50:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>2017-11-28 10:55:00</td>\n",
       "      <td>261.085000</td>\n",
       "      <td>261.100</td>\n",
       "      <td>-0.015000</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.997980e+17</td>\n",
       "      <td>join live fort myer arlington virginia</td>\n",
       "      <td>36009</td>\n",
       "      <td>4891</td>\n",
       "      <td>2017-08-22 01:00:00</td>\n",
       "      <td>2017-08-22 09:00:00</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>2017-08-22 09:05:00</td>\n",
       "      <td>243.670000</td>\n",
       "      <td>243.670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.939700e+17</td>\n",
       "      <td>thank nicole</td>\n",
       "      <td>43367</td>\n",
       "      <td>8275</td>\n",
       "      <td>2017-05-08 23:01:00</td>\n",
       "      <td>2017-05-09 07:01:00</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>07:01:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>2017-05-09 07:06:00</td>\n",
       "      <td>239.920000</td>\n",
       "      <td>239.875</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.819770e+17</td>\n",
       "      <td>thank shawn steel nice word</td>\n",
       "      <td>50956</td>\n",
       "      <td>7465</td>\n",
       "      <td>2017-03-07 20:44:00</td>\n",
       "      <td>2017-03-08 04:44:00</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>04:44:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>2017-03-08 04:49:00</td>\n",
       "      <td>236.913333</td>\n",
       "      <td>236.880</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.778460e+17</td>\n",
       "      <td>great night iowa special people thank</td>\n",
       "      <td>56446</td>\n",
       "      <td>8039</td>\n",
       "      <td>2017-06-22 11:11:00</td>\n",
       "      <td>2017-06-22 19:11:00</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>19:11:00</td>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>2017-06-22 19:16:00</td>\n",
       "      <td>242.905000</td>\n",
       "      <td>242.880</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                    text  favorites  retweets  \\\n",
       "0  9.353400e+17                              thank rand      42793      9125   \n",
       "1  8.997980e+17  join live fort myer arlington virginia      36009      4891   \n",
       "2  8.939700e+17                            thank nicole      43367      8275   \n",
       "3  8.819770e+17             thank shawn steel nice word      50956      7465   \n",
       "4  8.778460e+17   great night iowa special people thank      56446      8039   \n",
       "\n",
       "                  date       tweet_datetime   date_part time_part  hour  year  \\\n",
       "0  2017-11-28 02:50:00  2017-11-28 10:50:00  2017-11-28  10:50:00    10  2017   \n",
       "1  2017-08-22 01:00:00  2017-08-22 09:00:00  2017-08-22  09:00:00     9  2017   \n",
       "2  2017-05-08 23:01:00  2017-05-09 07:01:00  2017-05-09  07:01:00     7  2017   \n",
       "3  2017-03-07 20:44:00  2017-03-08 04:44:00  2017-03-08  04:44:00     4  2017   \n",
       "4  2017-06-22 11:11:00  2017-06-22 19:11:00  2017-06-22  19:11:00    19  2017   \n",
       "\n",
       "   month  topic  compound datetime_5mins_after  price_5mins_after  price_now  \\\n",
       "0     11      1    0.4199  2017-11-28 10:55:00         261.085000    261.100   \n",
       "1      8      2    0.2960  2017-08-22 09:05:00         243.670000    243.670   \n",
       "2      5      6    0.4199  2017-05-09 07:06:00         239.920000    239.875   \n",
       "3      3      3    0.6486  2017-03-08 04:49:00         236.913333    236.880   \n",
       "4      6      6    0.8622  2017-06-22 19:16:00         242.905000    242.880   \n",
       "\n",
       "   5mins_price_diff_abs  5mins_price_diff_perc  y_label  \n",
       "0             -0.015000              -0.000057       -1  \n",
       "1              0.000000               0.000000        0  \n",
       "2              0.045000               0.000188        1  \n",
       "3              0.033333               0.000141        1  \n",
       "4              0.025000               0.000103        1  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there were 51 rows for which tweets were empty so those rows have been dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to verify that there are no NA values\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.text\n",
    "y=df2.y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(stop_words=\"english\", max_features=1000)\n",
    "#Fit Count Vectorizer\n",
    "df_cv1 = count_vec.fit_transform(X)\n",
    "#Convert it to a pandas data frame\n",
    "df_cv2 = pd.DataFrame(df_cv1.toarray(), columns=count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2646, 1000)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "#test size is 20% of the dataset\n",
    "x_train,x_test,y_train,y_test = train_test_split(df2['text'], df2.y_label, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "#model = MultinomialNB()\n",
    "#Fit model with df_cv and y\n",
    "#model.fit(df_cv2, y)\n",
    "#score the model\n",
    "#model.score(df_cv2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Classifier: 48.87%\n",
      "\n",
      "Confusion Matrix of Logistic Regression Classifier:\n",
      "\n",
      "[[ 84   0 161]\n",
      " [  5   0  15]\n",
      " [ 90   0 175]]\n",
      "\n",
      "CLassification Report of Logistic Regression Classifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      0.34      0.40       245\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.50      0.66      0.57       265\n",
      "\n",
      "    accuracy                           0.49       530\n",
      "   macro avg       0.32      0.33      0.32       530\n",
      "weighted avg       0.47      0.49      0.47       530\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavanyajindal/Desktop/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression classification\n",
    "pipe1 = Pipeline([('vect', CountVectorizer(stop_words=\"english\", min_df=3, ngram_range=(1,1), max_features=200)), ('tfidf', TfidfTransformer()), ('model', LogisticRegression())])\n",
    "#models must be in the correct order, where previous models must have fit and transform functionality while \n",
    "#last model must only have fit\n",
    "model_lr = pipe1.fit(x_train, y_train)\n",
    "lr_pred = model_lr.predict(x_test)\n",
    "\n",
    "print(\"Accuracy of Logistic Regression Classifier: {}%\".format(round(accuracy_score(y_test, lr_pred)*100,2)))\n",
    "print(\"\\nConfusion Matrix of Logistic Regression Classifier:\\n\")\n",
    "print(confusion_matrix(y_test, lr_pred))\n",
    "print(\"\\nCLassification Report of Logistic Regression Classifier:\\n\")\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier: 51.32%\n",
      "\n",
      "Confusion Matrix of Naive Bayes Classifier:\n",
      "\n",
      "[[ 78   0 167]\n",
      " [  4   0  16]\n",
      " [ 71   0 194]]\n",
      "\n",
      "Classification Report of Naive Bayes Classifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.32      0.39       245\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.51      0.73      0.60       265\n",
      "\n",
      "    accuracy                           0.51       530\n",
      "   macro avg       0.34      0.35      0.33       530\n",
      "weighted avg       0.49      0.51      0.48       530\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavanyajindal/Desktop/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Naive-Bayes classification\n",
    "#more no. of features doesnt seem to improve accuracy after 5000\n",
    "#better results using cv + tfidftrransformer\n",
    "pipe3 = Pipeline([('vect', CountVectorizer(stop_words=\"english\",max_features=5000)), ('tfidf', TfidfTransformer()), ('model', MultinomialNB())])\n",
    "#pipe3 = Pipeline([('vect', CountVectorizer(stop_words=\"english\")),  ('model', MultinomialNB())])\n",
    "model_nb = pipe3.fit(x_train, y_train)\n",
    "nb_pred = model_nb.predict(x_test)\n",
    "\n",
    "print(\"Accuracy of Naive Bayes Classifier: {}%\".format(round(accuracy_score(y_test, nb_pred)*100,2)))\n",
    "print(\"\\nConfusion Matrix of Naive Bayes Classifier:\\n\")\n",
    "print(confusion_matrix(y_test, nb_pred))\n",
    "print(\"\\nClassification Report of Naive Bayes Classifier:\\n\")\n",
    "print(classification_report(y_test, nb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM Classifier: 50.19%\n",
      "\n",
      "Confusion Matrix of SVM Classifier:\n",
      "\n",
      "[[111   0 134]\n",
      " [ 10   0  10]\n",
      " [106   4 155]]\n",
      "\n",
      "Classification Report of SVM Classifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.49      0.45      0.47       245\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.52      0.58      0.55       265\n",
      "\n",
      "    accuracy                           0.50       530\n",
      "   macro avg       0.34      0.35      0.34       530\n",
      "weighted avg       0.49      0.50      0.49       530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Support Vector classification\n",
    "#accuracy score is better without applying the TFIDFTRANSFORMER()\n",
    "pipe2 = Pipeline([('vect', CountVectorizer(stop_words=\"english\")), ('tfidf', TfidfTransformer()), ('model', LinearSVC())])\n",
    "#pipe2 = Pipeline([('vect', CountVectorizer(stop_words=\"english\")),  ('model', LinearSVC())])\n",
    "model_svc = pipe2.fit(x_train, y_train)\n",
    "svc_pred = model_svc.predict(x_test)\n",
    "\n",
    "print(\"Accuracy of SVM Classifier: {}%\".format(round(accuracy_score(y_test, svc_pred)*100,2)))\n",
    "print(\"\\nConfusion Matrix of SVM Classifier:\\n\")\n",
    "print(confusion_matrix(y_test, svc_pred))\n",
    "print(\"\\nClassification Report of SVM Classifier:\\n\")\n",
    "print(classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 mins before after price change case (df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` need to run either 3 classes or 5 classes at a time cause it'll get overwritten as variable, df names used \n",
    "  are the same `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"tweets_stocks_combined_final_15mins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2612, 19)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_datetime</th>\n",
       "      <th>date_part</th>\n",
       "      <th>time_part</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>compound</th>\n",
       "      <th>datetime_15mins_after</th>\n",
       "      <th>price_15mins_after</th>\n",
       "      <th>price_now</th>\n",
       "      <th>15mins_price_diff_abs</th>\n",
       "      <th>15mins_price_diff_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.353400e+17</td>\n",
       "      <td>thank rand</td>\n",
       "      <td>42793</td>\n",
       "      <td>9125</td>\n",
       "      <td>2017-11-28 02:50:00</td>\n",
       "      <td>2017-11-28 10:50:00</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>10:50:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>2017-11-28 11:05:00</td>\n",
       "      <td>261.150000</td>\n",
       "      <td>261.100</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.997980e+17</td>\n",
       "      <td>join live fort myer arlington virginia</td>\n",
       "      <td>36009</td>\n",
       "      <td>4891</td>\n",
       "      <td>2017-08-22 01:00:00</td>\n",
       "      <td>2017-08-22 09:00:00</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>2017-08-22 09:15:00</td>\n",
       "      <td>243.630000</td>\n",
       "      <td>243.670</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>-0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.939700e+17</td>\n",
       "      <td>thank nicole</td>\n",
       "      <td>43367</td>\n",
       "      <td>8275</td>\n",
       "      <td>2017-05-08 23:01:00</td>\n",
       "      <td>2017-05-09 07:01:00</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>07:01:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>2017-05-09 07:16:00</td>\n",
       "      <td>239.940000</td>\n",
       "      <td>239.875</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.819770e+17</td>\n",
       "      <td>thank shawn steel nice word</td>\n",
       "      <td>50956</td>\n",
       "      <td>7465</td>\n",
       "      <td>2017-03-07 20:44:00</td>\n",
       "      <td>2017-03-08 04:44:00</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>04:44:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>2017-03-08 04:59:00</td>\n",
       "      <td>236.915000</td>\n",
       "      <td>236.880</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.778460e+17</td>\n",
       "      <td>great night iowa special people thank</td>\n",
       "      <td>56446</td>\n",
       "      <td>8039</td>\n",
       "      <td>2017-06-22 11:11:00</td>\n",
       "      <td>2017-06-22 19:11:00</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>19:11:00</td>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>2017-06-22 19:26:00</td>\n",
       "      <td>242.893333</td>\n",
       "      <td>242.880</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                    text  favorites  retweets  \\\n",
       "0  9.353400e+17                              thank rand      42793      9125   \n",
       "1  8.997980e+17  join live fort myer arlington virginia      36009      4891   \n",
       "2  8.939700e+17                            thank nicole      43367      8275   \n",
       "3  8.819770e+17             thank shawn steel nice word      50956      7465   \n",
       "4  8.778460e+17   great night iowa special people thank      56446      8039   \n",
       "\n",
       "                  date       tweet_datetime   date_part time_part  hour  year  \\\n",
       "0  2017-11-28 02:50:00  2017-11-28 10:50:00  2017-11-28  10:50:00    10  2017   \n",
       "1  2017-08-22 01:00:00  2017-08-22 09:00:00  2017-08-22  09:00:00     9  2017   \n",
       "2  2017-05-08 23:01:00  2017-05-09 07:01:00  2017-05-09  07:01:00     7  2017   \n",
       "3  2017-03-07 20:44:00  2017-03-08 04:44:00  2017-03-08  04:44:00     4  2017   \n",
       "4  2017-06-22 11:11:00  2017-06-22 19:11:00  2017-06-22  19:11:00    19  2017   \n",
       "\n",
       "   month  topic  compound datetime_15mins_after  price_15mins_after  \\\n",
       "0     11      1    0.4199   2017-11-28 11:05:00          261.150000   \n",
       "1      8      2    0.2960   2017-08-22 09:15:00          243.630000   \n",
       "2      5      6    0.4199   2017-05-09 07:16:00          239.940000   \n",
       "3      3      3    0.6486   2017-03-08 04:59:00          236.915000   \n",
       "4      6      6    0.8622   2017-06-22 19:26:00          242.893333   \n",
       "\n",
       "   price_now  15mins_price_diff_abs  15mins_price_diff_perc  \n",
       "0    261.100               0.050000                0.000191  \n",
       "1    243.670              -0.040000               -0.000164  \n",
       "2    239.875               0.065000                0.000271  \n",
       "3    236.880               0.035000                0.000148  \n",
       "4    242.880               0.013333                0.000055  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abs_diff has been calculated as price_20mins after - price now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.011220301969200505"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df1.loc[:,\"15mins_price_diff_perc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009678653404743802"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df1.loc[:,\"15mins_price_diff_perc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2612, 18)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list of values for the y label for each row\n",
    "target_value2=[]\n",
    "for i in range(0,2612):\n",
    "    \n",
    "    if (df1.loc[i,\"percentage_price_change\"]>0)==True:\n",
    "        target_value2.append(1)\n",
    "        i+=1\n",
    "    elif (df1.loc[i,\"percentage_price_change\"]<0)==True:\n",
    "        target_value2.append(-1)\n",
    "    else:\n",
    "        target_value2.append(0)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2612"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df1[df1.percentage_price_change != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for the y_label \n",
    "df1.loc[:,'y_label'] = target_value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_values=[]\n",
    "for i in range(0,2612):\n",
    "    rounded1 = df1.loc[i,\"15mins_price_diff_perc\"]*100\n",
    "  # rounded2 = round(rounded1,3)\n",
    "    percentage_values.append(rounded1)\n",
    "    i+=1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for the rounded_values\n",
    "df1.loc[:,'percentage_price_change'] = percentage_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-0.0==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#round(2.169999999999959,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rounded_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_datetime</th>\n",
       "      <th>date_part</th>\n",
       "      <th>time_part</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>compound</th>\n",
       "      <th>datetime_15mins_after</th>\n",
       "      <th>price_15mins_after</th>\n",
       "      <th>price_now</th>\n",
       "      <th>15mins_price_diff_abs</th>\n",
       "      <th>15mins_price_diff_perc</th>\n",
       "      <th>percentage_price_change</th>\n",
       "      <th>y_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.353400e+17</td>\n",
       "      <td>thank rand</td>\n",
       "      <td>42793</td>\n",
       "      <td>9125</td>\n",
       "      <td>2017-11-28 02:50:00</td>\n",
       "      <td>2017-11-28 10:50:00</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>10:50:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>2017-11-28 11:05:00</td>\n",
       "      <td>261.150000</td>\n",
       "      <td>261.100</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.019150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.997980e+17</td>\n",
       "      <td>join live fort myer arlington virginia</td>\n",
       "      <td>36009</td>\n",
       "      <td>4891</td>\n",
       "      <td>2017-08-22 01:00:00</td>\n",
       "      <td>2017-08-22 09:00:00</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>2017-08-22 09:15:00</td>\n",
       "      <td>243.630000</td>\n",
       "      <td>243.670</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.016416</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.939700e+17</td>\n",
       "      <td>thank nicole</td>\n",
       "      <td>43367</td>\n",
       "      <td>8275</td>\n",
       "      <td>2017-05-08 23:01:00</td>\n",
       "      <td>2017-05-09 07:01:00</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>07:01:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>2017-05-09 07:16:00</td>\n",
       "      <td>239.940000</td>\n",
       "      <td>239.875</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.027097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.819770e+17</td>\n",
       "      <td>thank shawn steel nice word</td>\n",
       "      <td>50956</td>\n",
       "      <td>7465</td>\n",
       "      <td>2017-03-07 20:44:00</td>\n",
       "      <td>2017-03-08 04:44:00</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>04:44:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>2017-03-08 04:59:00</td>\n",
       "      <td>236.915000</td>\n",
       "      <td>236.880</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.014775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.778460e+17</td>\n",
       "      <td>great night iowa special people thank</td>\n",
       "      <td>56446</td>\n",
       "      <td>8039</td>\n",
       "      <td>2017-06-22 11:11:00</td>\n",
       "      <td>2017-06-22 19:11:00</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>19:11:00</td>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>2017-06-22 19:26:00</td>\n",
       "      <td>242.893333</td>\n",
       "      <td>242.880</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                    text  favorites  retweets  \\\n",
       "0  9.353400e+17                              thank rand      42793      9125   \n",
       "1  8.997980e+17  join live fort myer arlington virginia      36009      4891   \n",
       "2  8.939700e+17                            thank nicole      43367      8275   \n",
       "3  8.819770e+17             thank shawn steel nice word      50956      7465   \n",
       "4  8.778460e+17   great night iowa special people thank      56446      8039   \n",
       "\n",
       "                  date       tweet_datetime   date_part time_part  hour  year  \\\n",
       "0  2017-11-28 02:50:00  2017-11-28 10:50:00  2017-11-28  10:50:00    10  2017   \n",
       "1  2017-08-22 01:00:00  2017-08-22 09:00:00  2017-08-22  09:00:00     9  2017   \n",
       "2  2017-05-08 23:01:00  2017-05-09 07:01:00  2017-05-09  07:01:00     7  2017   \n",
       "3  2017-03-07 20:44:00  2017-03-08 04:44:00  2017-03-08  04:44:00     4  2017   \n",
       "4  2017-06-22 11:11:00  2017-06-22 19:11:00  2017-06-22  19:11:00    19  2017   \n",
       "\n",
       "   month  topic  compound datetime_15mins_after  price_15mins_after  \\\n",
       "0     11      1    0.4199   2017-11-28 11:05:00          261.150000   \n",
       "1      8      2    0.2960   2017-08-22 09:15:00          243.630000   \n",
       "2      5      6    0.4199   2017-05-09 07:16:00          239.940000   \n",
       "3      3      3    0.6486   2017-03-08 04:59:00          236.915000   \n",
       "4      6      6    0.8622   2017-06-22 19:26:00          242.893333   \n",
       "\n",
       "   price_now  15mins_price_diff_abs  15mins_price_diff_perc  \\\n",
       "0    261.100               0.050000                0.000191   \n",
       "1    243.670              -0.040000               -0.000164   \n",
       "2    239.875               0.065000                0.000271   \n",
       "3    236.880               0.035000                0.000148   \n",
       "4    242.880               0.013333                0.000055   \n",
       "\n",
       "   percentage_price_change  y_label  \n",
       "0                 0.019150        1  \n",
       "1                -0.016416       -1  \n",
       "2                 0.027097        1  \n",
       "3                 0.014775        1  \n",
       "4                 0.005490        1  "
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#51 tweets dont exist again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavanyajindal/Desktop/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_new.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2502, 20)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = df_new.text\n",
    "y_ =df_new.y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "#test size is 20% of the dataset\n",
    "x_train1,x_test1,y_train1,y_test1 = train_test_split(df_new['text'], df_new.y_label, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Classifier: 52.89%\n",
      "\n",
      "Confusion Matrix of Logistic Regression Classifier:\n",
      "\n",
      "[[ 77 170]\n",
      " [ 66 188]]\n",
      "\n",
      "CLassification Report of Logistic Regression Classifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.31      0.39       247\n",
      "           1       0.53      0.74      0.61       254\n",
      "\n",
      "    accuracy                           0.53       501\n",
      "   macro avg       0.53      0.53      0.50       501\n",
      "weighted avg       0.53      0.53      0.51       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression classification\n",
    "pipe1_ = Pipeline([('vect', CountVectorizer(stop_words=\"english\", min_df=3, ngram_range=(1,1), max_features=200)), ('tfidf', TfidfTransformer()), ('model1', LogisticRegression())])\n",
    "#models must be in the correct order, where previous models must have fit and transform functionality while \n",
    "#last model must only have fit\n",
    "model_lr1 = pipe1_.fit(x_train1, y_train1)\n",
    "lr_pred1 = model_lr1.predict(x_test1)\n",
    "\n",
    "print(\"Accuracy of Logistic Regression Classifier: {}%\".format(round(accuracy_score(y_test1, lr_pred1)*100,2)))\n",
    "print(\"\\nConfusion Matrix of Logistic Regression Classifier:\\n\")\n",
    "print(confusion_matrix(y_test1, lr_pred1))\n",
    "print(\"\\nCLassification Report of Logistic Regression Classifier:\\n\")\n",
    "print(classification_report(y_test1, lr_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier: 51.7%\n",
      "\n",
      "Confusion Matrix of Naive Bayes Classifier:\n",
      "\n",
      "[[ 48 199]\n",
      " [ 43 211]]\n",
      "\n",
      "Classification Report of Naive Bayes Classifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.19      0.28       247\n",
      "           1       0.51      0.83      0.64       254\n",
      "\n",
      "    accuracy                           0.52       501\n",
      "   macro avg       0.52      0.51      0.46       501\n",
      "weighted avg       0.52      0.52      0.46       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive-Bayes classification\n",
    "#more no. of features doesnt seem to improve accuracy after 5000\n",
    "#better results using cv + tfidftrransformer\n",
    "pipe3_ = Pipeline([('vect', CountVectorizer(stop_words=\"english\",max_features=5000)), ('tfidf', TfidfTransformer()), ('model2', MultinomialNB())])\n",
    "#pipe3 = Pipeline([('vect', CountVectorizer(stop_words=\"english\")),  ('model', MultinomialNB())])\n",
    "model_nb1 = pipe3_.fit(x_train1, y_train1)\n",
    "nb_pred1 = model_nb1.predict(x_test1)\n",
    "\n",
    "print(\"Accuracy of Naive Bayes Classifier: {}%\".format(round(accuracy_score(y_test1, nb_pred1)*100,2)))\n",
    "print(\"\\nConfusion Matrix of Naive Bayes Classifier:\\n\")\n",
    "print(confusion_matrix(y_test1, nb_pred1))\n",
    "print(\"\\nClassification Report of Naive Bayes Classifier:\\n\")\n",
    "print(classification_report(y_test1, nb_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM Classifier: 50.3%\n",
      "\n",
      "Confusion Matrix of SVM Classifier:\n",
      "\n",
      "[[ 98 149]\n",
      " [100 154]]\n",
      "\n",
      "Classification Report of SVM Classifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.49      0.40      0.44       247\n",
      "           1       0.51      0.61      0.55       254\n",
      "\n",
      "    accuracy                           0.50       501\n",
      "   macro avg       0.50      0.50      0.50       501\n",
      "weighted avg       0.50      0.50      0.50       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Support Vector classification\n",
    "#accuracy score is better without applying the TFIDFTRANSFORMER()\n",
    "pipe2_ = Pipeline([('vect', CountVectorizer(stop_words=\"english\")), ('tfidf', TfidfTransformer()), ('model3', LinearSVC())])\n",
    "#pipe2 = Pipeline([('vect', CountVectorizer(stop_words=\"english\")),  ('model', LinearSVC())])\n",
    "model_svc1 = pipe2_.fit(x_train1, y_train1)\n",
    "svc_pred1 = model_svc1.predict(x_test1)\n",
    "\n",
    "print(\"Accuracy of SVM Classifier: {}%\".format(round(accuracy_score(y_test1, svc_pred1)*100,2)))\n",
    "print(\"\\nConfusion Matrix of SVM Classifier:\\n\")\n",
    "print(confusion_matrix(y_test1, svc_pred1))\n",
    "print(\"\\nClassification Report of SVM Classifier:\\n\")\n",
    "print(classification_report(y_test1, svc_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 mins one - can ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"tweets_stocks_combined_final_20mins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorized into 5 classes (-2,-1,0,1,2) since range was bigger this time\n",
    "target_value3=[]\n",
    "for i in range(0,2577):\n",
    "    \n",
    "    if ((df1.loc[i,\"20mins_price_diff_abs\"]>0) and (df1.loc[i,\"20mins_price_diff_abs\"]<1.5))==True:\n",
    "        target_value3.append(1)\n",
    "        i+=1\n",
    "    elif (df1.loc[i,\"20mins_price_diff_abs\"]>=1.5)==True:\n",
    "        target_value3.append(2)\n",
    "        i+=1\n",
    "    elif (df1.loc[i,\"20mins_price_diff_abs\"]<-1.5)==True:\n",
    "        target_value3.append(-2)\n",
    "        i+=1\n",
    "    elif ((df1.loc[i,\"20mins_price_diff_abs\"]<0) and (df1.loc[i,\"20mins_price_diff_abs\"]>=-1.5))==True:\n",
    "        target_value3.append(-1)\n",
    "    \n",
    "    else:\n",
    "        target_value3.append(0)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[:,'y_label'] = target_value3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = df1.text\n",
    "y_ =df1.y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "#test size is 20% of the dataset\n",
    "x_train1,x_test1,y_train1,y_test1 = train_test_split(df1['text'], df1.y_label, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Classifier: 47.83%\n",
      "\n",
      "Confusion Matrix of Logistic Regression Classifier:\n",
      "\n",
      "[[  0   1   0   0   0]\n",
      " [  0  65   0 154   0]\n",
      " [  0   0   0  11   0]\n",
      " [  0  97   0 177   0]\n",
      " [  0   0   0   1   0]]\n",
      "\n",
      "CLassification Report of Logistic Regression Classifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.00      0.00      0.00         1\n",
      "          -1       0.40      0.30      0.34       219\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.52      0.65      0.57       274\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.48       506\n",
      "   macro avg       0.18      0.19      0.18       506\n",
      "weighted avg       0.45      0.48      0.46       506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavanyajindal/Desktop/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression classification\n",
    "pipe1_ = Pipeline([('vect', CountVectorizer(stop_words=\"english\", min_df=3, ngram_range=(1,1), max_features=200)), ('tfidf', TfidfTransformer()), ('model', LogisticRegression())])\n",
    "#models must be in the correct order, where previous models must have fit and transform functionality while \n",
    "#last model must only have fit\n",
    "model_lr1 = pipe1_.fit(x_train1, y_train1)\n",
    "lr_pred1 = model_lr1.predict(x_test1)\n",
    "\n",
    "print(\"Accuracy of Logistic Regression Classifier: {}%\".format(round(accuracy_score(y_test1, lr_pred1)*100,2)))\n",
    "print(\"\\nConfusion Matrix of Logistic Regression Classifier:\\n\")\n",
    "print(confusion_matrix(y_test1, lr_pred1))\n",
    "print(\"\\nCLassification Report of Logistic Regression Classifier:\\n\")\n",
    "print(classification_report(y_test1, lr_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier: 55.53%\n",
      "\n",
      "Confusion Matrix of Naive Bayes Classifier:\n",
      "\n",
      "[[  0   0   0   1   0]\n",
      " [  0  49   0 170   0]\n",
      " [  0   0   0  11   0]\n",
      " [  0  42   0 232   0]\n",
      " [  0   0   0   1   0]]\n",
      "\n",
      "Classification Report of Naive Bayes Classifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.00      0.00      0.00         1\n",
      "          -1       0.54      0.22      0.32       219\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.56      0.85      0.67       274\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56       506\n",
      "   macro avg       0.22      0.21      0.20       506\n",
      "weighted avg       0.54      0.56      0.50       506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavanyajindal/Desktop/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Naive-Bayes classification\n",
    "#more no. of features doesnt seem to improve accuracy after 5000\n",
    "#better results using cv + tfidftrransformer\n",
    "pipe3_ = Pipeline([('vect', CountVectorizer(stop_words=\"english\",max_features=5000)), ('tfidf', TfidfTransformer()), ('model', MultinomialNB())])\n",
    "#pipe3 = Pipeline([('vect', CountVectorizer(stop_words=\"english\")),  ('model', MultinomialNB())])\n",
    "model_nb1 = pipe3_.fit(x_train1, y_train1)\n",
    "nb_pred1 = model_nb1.predict(x_test1)\n",
    "\n",
    "print(\"Accuracy of Naive Bayes Classifier: {}%\".format(round(accuracy_score(y_test1, nb_pred1)*100,2)))\n",
    "print(\"\\nConfusion Matrix of Naive Bayes Classifier:\\n\")\n",
    "print(confusion_matrix(y_test1, nb_pred1))\n",
    "print(\"\\nClassification Report of Naive Bayes Classifier:\\n\")\n",
    "print(classification_report(y_test1, nb_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM Classifier: 54.35%\n",
      "\n",
      "Confusion Matrix of SVM Classifier:\n",
      "\n",
      "[[  0   0   0   1   0]\n",
      " [  0  99   0 120   0]\n",
      " [  0   2   0   9   0]\n",
      " [  0  98   0 176   0]\n",
      " [  0   0   0   1   0]]\n",
      "\n",
      "Classification Report of SVM Classifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.00      0.00      0.00         1\n",
      "          -1       0.50      0.45      0.47       219\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.57      0.64      0.61       274\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.54       506\n",
      "   macro avg       0.21      0.22      0.22       506\n",
      "weighted avg       0.53      0.54      0.53       506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavanyajindal/Desktop/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Support Vector classification\n",
    "#accuracy score is better without applying the TFIDFTRANSFORMER()\n",
    "pipe2_ = Pipeline([('vect', CountVectorizer(stop_words=\"english\")), ('tfidf', TfidfTransformer()), ('model', LinearSVC())])\n",
    "#pipe2 = Pipeline([('vect', CountVectorizer(stop_words=\"english\")),  ('model', LinearSVC())])\n",
    "model_svc1 = pipe2_.fit(x_train1, y_train1)\n",
    "svc_pred1 = model_svc1.predict(x_test1)\n",
    "\n",
    "print(\"Accuracy of SVM Classifier: {}%\".format(round(accuracy_score(y_test1, svc_pred1)*100,2)))\n",
    "print(\"\\nConfusion Matrix of SVM Classifier:\\n\")\n",
    "print(confusion_matrix(y_test1, svc_pred1))\n",
    "print(\"\\nClassification Report of SVM Classifier:\\n\")\n",
    "print(classification_report(y_test1, svc_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.11230292, -7.70683781, -8.11230292, ..., -7.01369063,\n",
       "        -7.88915937, -7.10070201],\n",
       "       [-7.73236922, -7.03922204, -6.34607486, ..., -7.73236922,\n",
       "        -7.73236922, -6.63375693],\n",
       "       [-8.02059915, -7.83827759, -7.55059552, ..., -6.99097973,\n",
       "        -7.43281248, -8.02059915]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2526.000000\n",
       "mean        0.008803\n",
       "std         0.244648\n",
       "min        -3.670000\n",
       "25%        -0.030000\n",
       "50%         0.001246\n",
       "75%         0.050000\n",
       "max         2.170000\n",
       "Name: 20mins_price_diff_abs, dtype: float64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['20mins_price_diff_abs'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
